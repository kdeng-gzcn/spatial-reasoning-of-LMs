{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e1f1e6d",
   "metadata": {},
   "source": [
    "# Refactor Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "748e743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "res_dir = Path(\"/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eabe89a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "def _read_c2(dir: Path):\n",
    "    big_table = []\n",
    "    for eval_metric_dir in dir.iterdir():\n",
    "        if eval_metric_dir.is_dir():\n",
    "            for dataset_dir in eval_metric_dir.iterdir():\n",
    "                if dataset_dir.is_dir():\n",
    "                    for model_dir in dataset_dir.iterdir():\n",
    "                        if model_dir.is_dir():\n",
    "                            for tau_dir in model_dir.iterdir():\n",
    "                                if tau_dir.is_dir():\n",
    "                                    inf_file = tau_dir / \"inference.jsonl\"\n",
    "                                    temp_table = []\n",
    "                                    with jsonlines.open(inf_file) as reader:\n",
    "                                        for obj in reader:\n",
    "                                            obj[\"task\"] = \"c2\"\n",
    "                                            obj[\"model\"] = model_dir.name\n",
    "                                            obj[\"dataset\"] = dataset_dir.name\n",
    "                                            obj[\"eval_metric\"] = eval_metric_dir.name\n",
    "                                            obj[\"tau\"] = tau_dir.name\n",
    "                                            obj[\"is_trap\"] = True if \"w-trap\" in dir.parent.name else False\n",
    "                                            temp_table.append(obj)\n",
    "                                    big_table.extend(temp_table)\n",
    "    return big_table\n",
    "\n",
    "\n",
    "def _read_c1(dir: Path):\n",
    "    big_table = []\n",
    "    for dataset_dir in dir.iterdir():\n",
    "        if dataset_dir.is_dir():\n",
    "            for model_dir in dataset_dir.iterdir():\n",
    "                if model_dir.is_dir():\n",
    "                    for prompt_level_dir in model_dir.iterdir():\n",
    "                        if prompt_level_dir.is_dir():\n",
    "                            for dof_dir in prompt_level_dir.iterdir():\n",
    "                                if dof_dir.is_dir():\n",
    "                                    inf_file = dof_dir / \"inference.jsonl\"\n",
    "                                    with jsonlines.open(inf_file) as reader:\n",
    "                                        for obj in reader:\n",
    "                                            obj[\"task\"] = \"c1\"\n",
    "                                            obj[\"model\"] = model_dir.name\n",
    "                                            obj[\"dataset\"] = dataset_dir.name\n",
    "                                            obj[\"eval_metric\"] = dof_dir.name\n",
    "                                            obj[\"prompt_level\"] = prompt_level_dir.name\n",
    "                                            obj[\"is_trap\"] = True if \"w-trap\" in dir.parent.name else False\n",
    "                                            big_table.append(obj)\n",
    "    return big_table\n",
    "\n",
    "\n",
    "def _read_c1_cv(dir: Path):\n",
    "    big_table = []\n",
    "    for dataset_dir in dir.iterdir():\n",
    "        if dataset_dir.is_dir():\n",
    "            for model_dir in dataset_dir.iterdir():\n",
    "                if model_dir.is_dir():\n",
    "                    for dof_dir in model_dir.iterdir():\n",
    "                        if dof_dir.is_dir():\n",
    "                            inf_file = dof_dir / \"inference.jsonl\"\n",
    "                            with jsonlines.open(inf_file) as reader:\n",
    "                                for obj in reader:\n",
    "                                    obj[\"task\"] = \"c1\"\n",
    "                                    obj[\"model\"] = model_dir.name\n",
    "                                    obj[\"dataset\"] = dataset_dir.name\n",
    "                                    obj[\"eval_metric\"] = dof_dir.name\n",
    "                                    big_table.append(obj)\n",
    "    return big_table\n",
    "\n",
    "def _read_c2_cv(dir: Path):\n",
    "    big_table = []\n",
    "    for dataset_dir in dir.iterdir():\n",
    "        if dataset_dir.is_dir():\n",
    "            for tau_dir in dataset_dir.iterdir():\n",
    "                if tau_dir.is_dir():\n",
    "                    for model_dir in tau_dir.iterdir():\n",
    "                        if model_dir.is_dir():\n",
    "                            for eval_metric_dir in model_dir.iterdir():\n",
    "                                if eval_metric_dir.is_dir():\n",
    "                                    inf_file = eval_metric_dir / \"inference.jsonl\"\n",
    "                                    with jsonlines.open(inf_file) as reader:\n",
    "                                        for obj in reader:\n",
    "                                            obj[\"task\"] = \"c2\"\n",
    "                                            obj[\"model\"] = model_dir.name\n",
    "                                            obj[\"dataset\"] = dataset_dir.name\n",
    "                                            obj[\"eval_metric\"] = eval_metric_dir.name\n",
    "                                            obj[\"tau\"] = tau_dir.name\n",
    "                                            big_table.append(obj)\n",
    "    return big_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e5e4cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = _read_c1(res_dir / \"final-table-w-trap/single-dof-cls\") + _read_c1(res_dir / \"final-table-wo-trap/single-dof-cls\") + _read_c1_cv(res_dir / \"final-table-cv-methods/single-dof-cls\")\n",
    "c2 = _read_c2(res_dir / \"final-table-w-trap/obj-centered-cls\") + _read_c2(res_dir / \"final-table-wo-trap/obj-centered-cls\") + _read_c2_cv(res_dir / \"final-table-cv-methods/obj-centered-cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "877d5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "big_table = pd.DataFrame(c1 + c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "30e559e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['scene', 'pair', 'tx', 'ty', 'tz', 'theta', 'phi', 'psi', 'tx_text',\n",
       "       'ty_text', 'tz_text', 'theta_text', 'phi_text', 'psi_text',\n",
       "       'significance', 'significance_text', 'significance_value', 'rsn',\n",
       "       'pred', 'label', 'is_correct', 'is_parse', 'round', 'task', 'model',\n",
       "       'dataset', 'eval_metric', 'prompt_level', 'is_trap', 'seq', 'hash_id',\n",
       "       'pred_val', 'label_val', 'is_valid', 'distance', 'angle', 'tau'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "82cadcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table.to_json(res_dir / \"main_results.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053b79c",
   "metadata": {},
   "source": [
    "## Start Data Analysis!!!\n",
    "\n",
    "The default setup:\n",
    "- for c1: dataset + model + eval_dof -- acc. (default is prompt_level = zero-shot + is_trap = false)\n",
    "- for c2: dataset + model + evel_dof + tau -- acc. (default is is_trap = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3d32265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_df = pd.DataFrame(c1)\n",
    "c2_df = pd.DataFrame(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "64f37667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "Qwen2.5-VL-72B-Instruct           8466\n",
       "Qwen2.5-VL-32B-Instruct           7288\n",
       "gpt-4o                            5408\n",
       "llava-onevision-qwen2-7b-ov-hf    5408\n",
       "SpaceQwen2.5-VL-3B-Instruct       5408\n",
       "Idefics3-8B-Llama3                5408\n",
       "Qwen2.5-VL-7B-Instruct            5408\n",
       "loftr                              474\n",
       "sift                               474\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_df[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0cad37",
   "metadata": {},
   "source": [
    "make nice table for final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ffad5ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/user/1483801110/ipykernel_218062/833211985.py:27: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  output = c1_nice_table.groupby([\"dataset\", \"model\", \"eval_metric\"], observed=True).apply(compute_metrics).pivot_table(index=[\"dataset\", \"model\"], columns=[\"eval_metric\"], values=[\"acc\", \"f1\"], observed=True)\n",
      "/local/user/1483801110/ipykernel_218062/833211985.py:29: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  avg_output = c1_nice_table.groupby([\"dataset\", \"model\"], observed=True).apply(compute_metrics)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# define some names\n",
    "c1_nice_table = c1_df.copy()\n",
    "model_list = [\n",
    "    \"sift\",\n",
    "    \"loftr\",\n",
    "    \"SpaceQwen2.5-VL-3B-Instruct\",\n",
    "    \"Idefics3-8B-Llama3\",\n",
    "    \"llava-onevision-qwen2-7b-ov-hf\",\n",
    "    \"Qwen2.5-VL-7B-Instruct\",\n",
    "    \"Qwen2.5-VL-32B-Instruct\",\n",
    "    \"Qwen2.5-VL-72B-Instruct\",\n",
    "    \"gpt-4o\"\n",
    "]\n",
    "c1_nice_table[\"model\"] = pd.Categorical(c1_nice_table[\"model\"], categories=model_list, ordered=True)\n",
    "\n",
    "# filter condition\n",
    "c1_nice_table = c1_nice_table[(c1_nice_table[\"prompt_level\"] == \"zero-shot\") | (c1_nice_table[\"prompt_level\"].isna())] # want cv-method and zero-shot for VLM\n",
    "c1_nice_table = c1_nice_table[c1_nice_table[\"is_trap\"].isna() | (c1_nice_table[\"is_trap\"] == False)] # wo trap is default\n",
    "\n",
    "def compute_metrics(g):\n",
    "    acc = g[\"is_correct\"].mean()\n",
    "    f1 = f1_score(g[\"label\"], g[\"pred\"], average=\"weighted\")\n",
    "    return pd.Series({\"acc\": acc, \"f1\": f1})\n",
    "\n",
    "output = c1_nice_table.groupby([\"dataset\", \"model\", \"eval_metric\"], observed=True).apply(compute_metrics).pivot_table(index=[\"dataset\", \"model\"], columns=[\"eval_metric\"], values=[\"acc\", \"f1\"], observed=True)\n",
    "\n",
    "avg_output = c1_nice_table.groupby([\"dataset\", \"model\"], observed=True).apply(compute_metrics)\n",
    "avg_output.columns = pd.MultiIndex.from_product([avg_output.columns.unique(), [\"avg\"]], names=[None, \"eval_metric\"])\n",
    "\n",
    "# post-process output\n",
    "output = output.round(2)\n",
    "avg_output = avg_output.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "aedc1ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.concat([output, avg_output], axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "78e0ca58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>avg</th>\n",
       "      <th>phi</th>\n",
       "      <th>psi</th>\n",
       "      <th>theta</th>\n",
       "      <th>tx</th>\n",
       "      <th>ty</th>\n",
       "      <th>tz</th>\n",
       "      <th>avg</th>\n",
       "      <th>phi</th>\n",
       "      <th>psi</th>\n",
       "      <th>theta</th>\n",
       "      <th>tx</th>\n",
       "      <th>ty</th>\n",
       "      <th>tz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">7-scenes</th>\n",
       "      <th>sift</th>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loftr</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpaceQwen2.5-VL-3B-Instruct</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idefics3-8B-Llama3</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava-onevision-qwen2-7b-ov-hf</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-7B-Instruct</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-32B-Instruct</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-72B-Instruct</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">scannet</th>\n",
       "      <th>sift</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loftr</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpaceQwen2.5-VL-3B-Instruct</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idefics3-8B-Llama3</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava-onevision-qwen2-7b-ov-hf</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-7B-Instruct</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-32B-Instruct</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-72B-Instruct</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">scannetpp</th>\n",
       "      <th>SpaceQwen2.5-VL-3B-Instruct</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idefics3-8B-Llama3</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava-onevision-qwen2-7b-ov-hf</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-7B-Instruct</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-32B-Instruct</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-72B-Instruct</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           acc                                \\\n",
       "eval_metric                                avg   phi   psi theta    tx    ty   \n",
       "dataset   model                                                                \n",
       "7-scenes  sift                            0.97  1.00  0.98  1.00  0.88  0.80   \n",
       "          loftr                           0.98  0.98  0.98  1.00  0.97  0.80   \n",
       "          SpaceQwen2.5-VL-3B-Instruct     0.53  0.55  0.48  0.43  0.66  0.50   \n",
       "          Idefics3-8B-Llama3              0.52  0.52  0.40  0.50  0.66  0.60   \n",
       "          llava-onevision-qwen2-7b-ov-hf  0.50  0.47  0.58  0.34  0.59  0.70   \n",
       "          Qwen2.5-VL-7B-Instruct          0.57  0.55  0.45  0.66  0.59  0.70   \n",
       "          Qwen2.5-VL-32B-Instruct         0.70  0.82  0.45  0.88  0.72  0.90   \n",
       "          Qwen2.5-VL-72B-Instruct         0.77  0.82  0.58  0.84  0.88  0.90   \n",
       "          gpt-4o                          0.76  0.90  0.45  0.84  0.88  1.00   \n",
       "scannet   sift                            0.83  0.90  0.91  0.83  0.69  0.67   \n",
       "          loftr                           0.94  1.00  0.97  0.97  0.85  0.67   \n",
       "          SpaceQwen2.5-VL-3B-Instruct     0.44  0.42  0.38  0.45  0.42  0.47   \n",
       "          Idefics3-8B-Llama3              0.51  0.53  0.50  0.52  0.50  0.47   \n",
       "          llava-onevision-qwen2-7b-ov-hf  0.58  0.60  0.56  0.47  0.67  0.53   \n",
       "          Qwen2.5-VL-7B-Instruct          0.72  0.68  0.56  0.90  0.71  0.73   \n",
       "          Qwen2.5-VL-32B-Instruct         0.82  0.85  0.59  0.97  0.83  0.87   \n",
       "          Qwen2.5-VL-72B-Instruct         0.82  0.92  0.29  0.97  0.89  0.84   \n",
       "          gpt-4o                          0.79  0.88  0.38  1.00  0.75  1.00   \n",
       "scannetpp SpaceQwen2.5-VL-3B-Instruct     0.55  0.50  0.50  0.60  0.50  0.50   \n",
       "          Idefics3-8B-Llama3              0.46  0.45  0.50  0.38  0.53  0.00   \n",
       "          llava-onevision-qwen2-7b-ov-hf  0.54  0.48  0.50  0.47  0.60  1.00   \n",
       "          Qwen2.5-VL-7B-Instruct          0.72  0.60  0.50  0.92  0.63  0.50   \n",
       "          Qwen2.5-VL-32B-Instruct         0.76  0.60  1.00  0.95  0.72  0.50   \n",
       "          Qwen2.5-VL-72B-Instruct         0.90  0.93  0.00  0.96  0.85  0.88   \n",
       "          gpt-4o                          0.88  0.83  0.50  0.97  0.85  1.00   \n",
       "\n",
       "                                                  f1                          \\\n",
       "eval_metric                                 tz   avg   phi   psi theta    tx   \n",
       "dataset   model                                                                \n",
       "7-scenes  sift                            1.00  0.97  1.00  0.98  1.00  0.87   \n",
       "          loftr                           1.00  0.98  0.98  0.98  1.00  0.97   \n",
       "          SpaceQwen2.5-VL-3B-Instruct     0.67  0.53  0.55  0.47  0.45  0.66   \n",
       "          Idefics3-8B-Llama3              0.72  0.53  0.52  0.40  0.52  0.66   \n",
       "          llava-onevision-qwen2-7b-ov-hf  0.56  0.42  0.30  0.55  0.29  0.44   \n",
       "          Qwen2.5-VL-7B-Instruct          0.67  0.56  0.50  0.50  0.67  0.49   \n",
       "          Qwen2.5-VL-32B-Instruct         0.44  0.69  0.81  0.38  0.88  0.72   \n",
       "          Qwen2.5-VL-72B-Instruct         0.72  0.79  0.82  0.64  0.88  0.89   \n",
       "          gpt-4o                          0.78  0.77  0.90  0.45  0.85  0.88   \n",
       "scannet   sift                            1.00  0.84  0.90  0.94  0.85  0.70   \n",
       "          loftr                           1.00  0.94  1.00  0.97  0.97  0.87   \n",
       "          SpaceQwen2.5-VL-3B-Instruct     0.58  0.44  0.42  0.39  0.46  0.43   \n",
       "          Idefics3-8B-Llama3              0.47  0.51  0.53  0.50  0.51  0.51   \n",
       "          llava-onevision-qwen2-7b-ov-hf  0.74  0.49  0.48  0.56  0.40  0.53   \n",
       "          Qwen2.5-VL-7B-Instruct          0.63  0.71  0.69  0.59  0.91  0.64   \n",
       "          Qwen2.5-VL-32B-Instruct         0.58  0.81  0.85  0.52  0.97  0.82   \n",
       "          Qwen2.5-VL-72B-Instruct         0.59  0.83  0.93  0.36  0.97  0.89   \n",
       "          gpt-4o                          0.53  0.79  0.88  0.39  1.00  0.76   \n",
       "scannetpp SpaceQwen2.5-VL-3B-Instruct     0.75  0.55  0.50  0.67  0.60  0.50   \n",
       "          Idefics3-8B-Llama3              0.62  0.47  0.45  0.67  0.39  0.53   \n",
       "          llava-onevision-qwen2-7b-ov-hf  0.75  0.44  0.34  0.67  0.40  0.47   \n",
       "          Qwen2.5-VL-7B-Instruct          0.88  0.67  0.55  0.67  0.92  0.53   \n",
       "          Qwen2.5-VL-32B-Instruct         0.81  0.75  0.59  1.00  0.95  0.71   \n",
       "          Qwen2.5-VL-72B-Instruct         0.96  0.90  0.93  0.00  0.98  0.85   \n",
       "          gpt-4o                          0.81  0.88  0.83  0.67  0.97  0.85   \n",
       "\n",
       "                                                      \n",
       "eval_metric                                 ty    tz  \n",
       "dataset   model                                       \n",
       "7-scenes  sift                            0.84  1.00  \n",
       "          loftr                           0.80  1.00  \n",
       "          SpaceQwen2.5-VL-3B-Instruct     0.52  0.67  \n",
       "          Idefics3-8B-Llama3              0.60  0.74  \n",
       "          llava-onevision-qwen2-7b-ov-hf  0.68  0.59  \n",
       "          Qwen2.5-VL-7B-Instruct          0.71  0.62  \n",
       "          Qwen2.5-VL-32B-Instruct         0.90  0.48  \n",
       "          Qwen2.5-VL-72B-Instruct         0.90  0.65  \n",
       "          gpt-4o                          1.00  0.80  \n",
       "scannet   sift                            0.66  1.00  \n",
       "          loftr                           0.68  1.00  \n",
       "          SpaceQwen2.5-VL-3B-Instruct     0.47  0.55  \n",
       "          Idefics3-8B-Llama3              0.46  0.48  \n",
       "          llava-onevision-qwen2-7b-ov-hf  0.37  0.73  \n",
       "          Qwen2.5-VL-7B-Instruct          0.73  0.59  \n",
       "          Qwen2.5-VL-32B-Instruct         0.90  0.61  \n",
       "          Qwen2.5-VL-72B-Instruct         0.90  0.62  \n",
       "          gpt-4o                          1.00  0.50  \n",
       "scannetpp SpaceQwen2.5-VL-3B-Instruct     0.50  0.75  \n",
       "          Idefics3-8B-Llama3              0.00  0.69  \n",
       "          llava-onevision-qwen2-7b-ov-hf  1.00  0.75  \n",
       "          Qwen2.5-VL-7B-Instruct          0.50  0.82  \n",
       "          Qwen2.5-VL-32B-Instruct         0.50  0.84  \n",
       "          Qwen2.5-VL-72B-Instruct         0.88  0.95  \n",
       "          gpt-4o                          1.00  0.83  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f8d64525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Results of C1 task with different models and evaluation metrics.}\n",
      "\\label{tab:c1_results}\n",
      "\\begin{tabular}{llcccccccccccccc}\n",
      "\\toprule\n",
      " &  & \\multicolumn{7}{r}{acc} & \\multicolumn{7}{r}{f1} \\\\\n",
      " & eval_metric & avg & phi & psi & theta & tx & ty & tz & avg & phi & psi & theta & tx & ty & tz \\\\\n",
      "dataset & model &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{9}{*}{7-scenes} & sift & 0.97 & 1.00 & 0.98 & 1.00 & 0.88 & 0.80 & 1.00 & 0.97 & 1.00 & 0.98 & 1.00 & 0.87 & 0.84 & 1.00 \\\\\n",
      " & loftr & 0.98 & 0.98 & 0.98 & 1.00 & 0.97 & 0.80 & 1.00 & 0.98 & 0.98 & 0.98 & 1.00 & 0.97 & 0.80 & 1.00 \\\\\n",
      " & SpaceQwen2.5-VL-3B-Instruct & 0.53 & 0.55 & 0.48 & 0.43 & 0.66 & 0.50 & 0.67 & 0.53 & 0.55 & 0.47 & 0.45 & 0.66 & 0.52 & 0.67 \\\\\n",
      " & Idefics3-8B-Llama3 & 0.52 & 0.52 & 0.40 & 0.50 & 0.66 & 0.60 & 0.72 & 0.53 & 0.52 & 0.40 & 0.52 & 0.66 & 0.60 & 0.74 \\\\\n",
      " & llava-onevision-qwen2-7b-ov-hf & 0.50 & 0.47 & 0.58 & 0.34 & 0.59 & 0.70 & 0.56 & 0.42 & 0.30 & 0.55 & 0.29 & 0.44 & 0.68 & 0.59 \\\\\n",
      " & Qwen2.5-VL-7B-Instruct & 0.57 & 0.55 & 0.45 & 0.66 & 0.59 & 0.70 & 0.67 & 0.56 & 0.50 & 0.50 & 0.67 & 0.49 & 0.71 & 0.62 \\\\\n",
      " & Qwen2.5-VL-32B-Instruct & 0.70 & 0.82 & 0.45 & 0.88 & 0.72 & 0.90 & 0.44 & 0.69 & 0.81 & 0.38 & 0.88 & 0.72 & 0.90 & 0.48 \\\\\n",
      " & Qwen2.5-VL-72B-Instruct & 0.77 & 0.82 & 0.58 & 0.84 & 0.88 & 0.90 & 0.72 & 0.79 & 0.82 & 0.64 & 0.88 & 0.89 & 0.90 & 0.65 \\\\\n",
      " & gpt-4o & 0.76 & 0.90 & 0.45 & 0.84 & 0.88 & 1.00 & 0.78 & 0.77 & 0.90 & 0.45 & 0.85 & 0.88 & 1.00 & 0.80 \\\\\n",
      "\\cline{1-16}\n",
      "\\multirow[t]{9}{*}{scannet} & sift & 0.83 & 0.90 & 0.91 & 0.83 & 0.69 & 0.67 & 1.00 & 0.84 & 0.90 & 0.94 & 0.85 & 0.70 & 0.66 & 1.00 \\\\\n",
      " & loftr & 0.94 & 1.00 & 0.97 & 0.97 & 0.85 & 0.67 & 1.00 & 0.94 & 1.00 & 0.97 & 0.97 & 0.87 & 0.68 & 1.00 \\\\\n",
      " & SpaceQwen2.5-VL-3B-Instruct & 0.44 & 0.42 & 0.38 & 0.45 & 0.42 & 0.47 & 0.58 & 0.44 & 0.42 & 0.39 & 0.46 & 0.43 & 0.47 & 0.55 \\\\\n",
      " & Idefics3-8B-Llama3 & 0.51 & 0.53 & 0.50 & 0.52 & 0.50 & 0.47 & 0.47 & 0.51 & 0.53 & 0.50 & 0.51 & 0.51 & 0.46 & 0.48 \\\\\n",
      " & llava-onevision-qwen2-7b-ov-hf & 0.58 & 0.60 & 0.56 & 0.47 & 0.67 & 0.53 & 0.74 & 0.49 & 0.48 & 0.56 & 0.40 & 0.53 & 0.37 & 0.73 \\\\\n",
      " & Qwen2.5-VL-7B-Instruct & 0.72 & 0.68 & 0.56 & 0.90 & 0.71 & 0.73 & 0.63 & 0.71 & 0.69 & 0.59 & 0.91 & 0.64 & 0.73 & 0.59 \\\\\n",
      " & Qwen2.5-VL-32B-Instruct & 0.82 & 0.85 & 0.59 & 0.97 & 0.83 & 0.87 & 0.58 & 0.81 & 0.85 & 0.52 & 0.97 & 0.82 & 0.90 & 0.61 \\\\\n",
      " & Qwen2.5-VL-72B-Instruct & 0.82 & 0.92 & 0.29 & 0.97 & 0.89 & 0.84 & 0.59 & 0.83 & 0.93 & 0.36 & 0.97 & 0.89 & 0.90 & 0.62 \\\\\n",
      " & gpt-4o & 0.79 & 0.88 & 0.38 & 1.00 & 0.75 & 1.00 & 0.53 & 0.79 & 0.88 & 0.39 & 1.00 & 0.76 & 1.00 & 0.50 \\\\\n",
      "\\cline{1-16}\n",
      "\\multirow[t]{7}{*}{scannetpp} & SpaceQwen2.5-VL-3B-Instruct & 0.55 & 0.50 & 0.50 & 0.60 & 0.50 & 0.50 & 0.75 & 0.55 & 0.50 & 0.67 & 0.60 & 0.50 & 0.50 & 0.75 \\\\\n",
      " & Idefics3-8B-Llama3 & 0.46 & 0.45 & 0.50 & 0.38 & 0.53 & 0.00 & 0.62 & 0.47 & 0.45 & 0.67 & 0.39 & 0.53 & 0.00 & 0.69 \\\\\n",
      " & llava-onevision-qwen2-7b-ov-hf & 0.54 & 0.48 & 0.50 & 0.47 & 0.60 & 1.00 & 0.75 & 0.44 & 0.34 & 0.67 & 0.40 & 0.47 & 1.00 & 0.75 \\\\\n",
      " & Qwen2.5-VL-7B-Instruct & 0.72 & 0.60 & 0.50 & 0.92 & 0.63 & 0.50 & 0.88 & 0.67 & 0.55 & 0.67 & 0.92 & 0.53 & 0.50 & 0.82 \\\\\n",
      " & Qwen2.5-VL-32B-Instruct & 0.76 & 0.60 & 1.00 & 0.95 & 0.72 & 0.50 & 0.81 & 0.75 & 0.59 & 1.00 & 0.95 & 0.71 & 0.50 & 0.84 \\\\\n",
      " & Qwen2.5-VL-72B-Instruct & 0.90 & 0.93 & 0.00 & 0.96 & 0.85 & 0.88 & 0.96 & 0.90 & 0.93 & 0.00 & 0.98 & 0.85 & 0.88 & 0.95 \\\\\n",
      " & gpt-4o & 0.88 & 0.83 & 0.50 & 0.97 & 0.85 & 1.00 & 0.81 & 0.88 & 0.83 & 0.67 & 0.97 & 0.85 & 1.00 & 0.83 \\\\\n",
      "\\cline{1-16}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output.to_latex(\n",
    "    column_format=\"ll\" + \"c\" * len(output.columns),\n",
    "    float_format=\"%.2f\",\n",
    "    label=\"tab:c1_results\",\n",
    "    caption=\"Results of C1 task with different models and evaluation metrics.\",\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb930f59",
   "metadata": {},
   "source": [
    "same for C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "52a019b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/user/1483801110/ipykernel_218062/1773341369.py:5: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  output = c2_nice_table.groupby([\"dataset\", \"model\", \"eval_metric\", \"tau\"], observed=True).apply(compute_metrics).pivot_table(index=[\"dataset\", \"model\"], columns=[\"eval_metric\", \"tau\"], values=[\"acc\", \"f1\"], observed=True)\n",
      "/local/user/1483801110/ipykernel_218062/1773341369.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  avg_output = c2_nice_table.groupby([\"dataset\", \"model\", \"eval_metric\"], observed=True).apply(compute_metrics).pivot_table(index=[\"dataset\", \"model\"], columns=[\"eval_metric\"], values=[\"acc\", \"f1\"], observed=True)\n"
     ]
    }
   ],
   "source": [
    "c2_nice_table = c2_df.copy()\n",
    "c2_nice_table = c2_nice_table[c2_nice_table[\"is_trap\"].isna() | (c2_nice_table[\"is_trap\"] == False)]\n",
    "c2_nice_table[\"model\"] = pd.Categorical(c2_nice_table[\"model\"], categories=model_list, ordered=True)\n",
    "\n",
    "output = c2_nice_table.groupby([\"dataset\", \"model\", \"eval_metric\", \"tau\"], observed=True).apply(compute_metrics).pivot_table(index=[\"dataset\", \"model\"], columns=[\"eval_metric\", \"tau\"], values=[\"acc\", \"f1\"], observed=True)\n",
    "output.columns = pd.MultiIndex.from_product([[\"acc\", \"f1\"], [\"phi\", \"tx\"], [\"15\", \"30\", \"45\", \"60\"]], names=[None, \"dof\", \"tau\"])\n",
    "\n",
    "avg_output = c2_nice_table.groupby([\"dataset\", \"model\", \"eval_metric\"], observed=True).apply(compute_metrics).pivot_table(index=[\"dataset\", \"model\"], columns=[\"eval_metric\"], values=[\"acc\", \"f1\"], observed=True)\n",
    "avg_output.columns = pd.MultiIndex.from_product([[\"acc\", \"f1\"], [\"phi\", \"tx\"], [\"avg\"]], names=[None, \"dof\", \"tau\"])\n",
    "\n",
    "output = output.round(2)\n",
    "\n",
    "avg_output = avg_output.round(2)\n",
    "\n",
    "output = pd.concat([output, avg_output], axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "52036bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"10\" halign=\"left\">f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>dof</th>\n",
       "      <th colspan=\"5\" halign=\"left\">phi</th>\n",
       "      <th colspan=\"5\" halign=\"left\">tx</th>\n",
       "      <th colspan=\"5\" halign=\"left\">phi</th>\n",
       "      <th colspan=\"5\" halign=\"left\">tx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>tau</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>45</th>\n",
       "      <th>60</th>\n",
       "      <th>avg</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>45</th>\n",
       "      <th>60</th>\n",
       "      <th>avg</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>45</th>\n",
       "      <th>60</th>\n",
       "      <th>avg</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>45</th>\n",
       "      <th>60</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">7-scenes</th>\n",
       "      <th>sift</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loftr</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpaceQwen2.5-VL-3B-Instruct</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idefics3-8B-Llama3</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava-onevision-qwen2-7b-ov-hf</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-7B-Instruct</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-32B-Instruct</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-72B-Instruct</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">scannet</th>\n",
       "      <th>sift</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loftr</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpaceQwen2.5-VL-3B-Instruct</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idefics3-8B-Llama3</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava-onevision-qwen2-7b-ov-hf</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-7B-Instruct</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-32B-Instruct</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-72B-Instruct</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          acc                                \\\n",
       "dof                                       phi                            tx   \n",
       "tau                                        15    30    45    60   avg    15   \n",
       "dataset  model                                                                \n",
       "7-scenes sift                            0.59  0.44  0.34  0.30  0.43  0.50   \n",
       "         loftr                           0.95  0.95  0.92  0.76  0.91  0.95   \n",
       "         SpaceQwen2.5-VL-3B-Instruct     0.63  0.60  0.60  0.61  0.61  0.40   \n",
       "         Idefics3-8B-Llama3              0.60  0.57  0.55  0.55  0.57  0.50   \n",
       "         llava-onevision-qwen2-7b-ov-hf  0.55  0.52  0.57  0.58  0.55  0.40   \n",
       "         Qwen2.5-VL-7B-Instruct          0.45  0.38  0.43  0.55  0.44  0.57   \n",
       "         Qwen2.5-VL-32B-Instruct         0.45  0.45  0.47  0.50  0.46  0.67   \n",
       "         Qwen2.5-VL-72B-Instruct         0.58  0.48  0.45  0.47  0.50  0.62   \n",
       "         gpt-4o                          0.62  0.37  0.60  0.50  0.52  0.65   \n",
       "scannet  sift                            0.18  0.17  0.15  0.11  0.15  0.22   \n",
       "         loftr                           0.95  0.77  0.69  0.55  0.75  0.93   \n",
       "         SpaceQwen2.5-VL-3B-Instruct     0.63  0.55  0.57  0.57  0.58  0.43   \n",
       "         Idefics3-8B-Llama3              0.52  0.47  0.45  0.45  0.47  0.48   \n",
       "         llava-onevision-qwen2-7b-ov-hf  0.55  0.45  0.45  0.53  0.50  0.43   \n",
       "         Qwen2.5-VL-7B-Instruct          0.33  0.45  0.53  0.40  0.42  0.63   \n",
       "         Qwen2.5-VL-32B-Instruct         0.42  0.38  0.38  0.47  0.41  0.52   \n",
       "         Qwen2.5-VL-72B-Instruct         0.40  0.40  0.43  0.45  0.42  0.60   \n",
       "         gpt-4o                          0.42  0.53  0.47  0.52  0.49  0.58   \n",
       "\n",
       "                                                                   f1        \\\n",
       "dof                                                               phi         \n",
       "tau                                        30    45    60   avg    15    30   \n",
       "dataset  model                                                                \n",
       "7-scenes sift                            0.42  0.38  0.21  0.39  0.72  0.56   \n",
       "         loftr                           0.95  0.90  0.79  0.91  0.97  0.96   \n",
       "         SpaceQwen2.5-VL-3B-Instruct     0.47  0.43  0.45  0.44  0.62  0.60   \n",
       "         Idefics3-8B-Llama3              0.45  0.48  0.42  0.47  0.60  0.57   \n",
       "         llava-onevision-qwen2-7b-ov-hf  0.48  0.43  0.42  0.44  0.55  0.52   \n",
       "         Qwen2.5-VL-7B-Instruct          0.55  0.58  0.45  0.55  0.32  0.26   \n",
       "         Qwen2.5-VL-32B-Instruct         0.57  0.47  0.34  0.53  0.44  0.46   \n",
       "         Qwen2.5-VL-72B-Instruct         0.50  0.53  0.42  0.53  0.57  0.48   \n",
       "         gpt-4o                          0.58  0.45  0.34  0.52  0.62  0.37   \n",
       "scannet  sift                            0.20  0.12  0.15  0.18  0.28  0.27   \n",
       "         loftr                           0.77  0.78  0.53  0.75  0.96  0.81   \n",
       "         SpaceQwen2.5-VL-3B-Instruct     0.53  0.55  0.48  0.50  0.63  0.54   \n",
       "         Idefics3-8B-Llama3              0.53  0.53  0.40  0.49  0.53  0.47   \n",
       "         llava-onevision-qwen2-7b-ov-hf  0.53  0.53  0.47  0.49  0.57  0.46   \n",
       "         Qwen2.5-VL-7B-Instruct          0.52  0.42  0.58  0.55  0.23  0.37   \n",
       "         Qwen2.5-VL-32B-Instruct         0.58  0.53  0.53  0.54  0.42  0.37   \n",
       "         Qwen2.5-VL-72B-Instruct         0.62  0.62  0.53  0.59  0.38  0.40   \n",
       "         gpt-4o                          0.48  0.47  0.48  0.51  0.44  0.52   \n",
       "\n",
       "                                                                             \\\n",
       "dof                                                          tx               \n",
       "tau                                        45    60   avg    15    30    45   \n",
       "dataset  model                                                                \n",
       "7-scenes sift                            0.46  0.42  0.56  0.61  0.53  0.50   \n",
       "         loftr                           0.95  0.82  0.93  0.97  0.96  0.93   \n",
       "         SpaceQwen2.5-VL-3B-Instruct     0.60  0.59  0.60  0.41  0.47  0.44   \n",
       "         Idefics3-8B-Llama3              0.55  0.55  0.57  0.49  0.45  0.49   \n",
       "         llava-onevision-qwen2-7b-ov-hf  0.57  0.58  0.55  0.41  0.49  0.44   \n",
       "         Qwen2.5-VL-7B-Instruct          0.31  0.43  0.32  0.48  0.46  0.55   \n",
       "         Qwen2.5-VL-32B-Instruct         0.47  0.51  0.46  0.66  0.56  0.48   \n",
       "         Qwen2.5-VL-72B-Instruct         0.45  0.47  0.49  0.62  0.50  0.54   \n",
       "         gpt-4o                          0.59  0.48  0.52  0.65  0.58  0.45   \n",
       "scannet  sift                            0.23  0.18  0.24  0.33  0.31  0.18   \n",
       "         loftr                           0.76  0.67  0.81  0.94  0.81  0.85   \n",
       "         SpaceQwen2.5-VL-3B-Instruct     0.56  0.54  0.57  0.45  0.54  0.56   \n",
       "         Idefics3-8B-Llama3              0.46  0.45  0.48  0.49  0.54  0.54   \n",
       "         llava-onevision-qwen2-7b-ov-hf  0.46  0.54  0.50  0.45  0.54  0.54   \n",
       "         Qwen2.5-VL-7B-Instruct          0.44  0.31  0.32  0.56  0.43  0.37   \n",
       "         Qwen2.5-VL-32B-Instruct         0.34  0.42  0.39  0.51  0.56  0.52   \n",
       "         Qwen2.5-VL-72B-Instruct         0.41  0.40  0.40  0.61  0.62  0.61   \n",
       "         gpt-4o                          0.48  0.52  0.49  0.59  0.48  0.47   \n",
       "\n",
       "                                                     \n",
       "dof                                                  \n",
       "tau                                        60   avg  \n",
       "dataset  model                                       \n",
       "7-scenes sift                            0.29  0.51  \n",
       "         loftr                           0.85  0.93  \n",
       "         SpaceQwen2.5-VL-3B-Instruct     0.45  0.44  \n",
       "         Idefics3-8B-Llama3              0.41  0.46  \n",
       "         llava-onevision-qwen2-7b-ov-hf  0.42  0.44  \n",
       "         Qwen2.5-VL-7B-Instruct          0.32  0.47  \n",
       "         Qwen2.5-VL-32B-Instruct         0.34  0.53  \n",
       "         Qwen2.5-VL-72B-Instruct         0.42  0.53  \n",
       "         gpt-4o                          0.35  0.53  \n",
       "scannet  sift                            0.24  0.28  \n",
       "         loftr                           0.65  0.82  \n",
       "         SpaceQwen2.5-VL-3B-Instruct     0.49  0.51  \n",
       "         Idefics3-8B-Llama3              0.41  0.49  \n",
       "         llava-onevision-qwen2-7b-ov-hf  0.47  0.50  \n",
       "         Qwen2.5-VL-7B-Instruct          0.52  0.48  \n",
       "         Qwen2.5-VL-32B-Instruct         0.51  0.52  \n",
       "         Qwen2.5-VL-72B-Instruct         0.54  0.60  \n",
       "         gpt-4o                          0.49  0.51  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6d725008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Results of C2 task with different models, evaluation metrics, and tau values.}\n",
      "\\label{tab:c2_results}\n",
      "\\begin{tabular}{llcccccccccccccccccccc}\n",
      "\\toprule\n",
      " &  & \\multicolumn{10}{r}{acc} & \\multicolumn{10}{r}{f1} \\\\\n",
      " & dof & \\multicolumn{5}{r}{phi} & \\multicolumn{5}{r}{tx} & \\multicolumn{5}{r}{phi} & \\multicolumn{5}{r}{tx} \\\\\n",
      " & tau & 15 & 30 & 45 & 60 & avg & 15 & 30 & 45 & 60 & avg & 15 & 30 & 45 & 60 & avg & 15 & 30 & 45 & 60 & avg \\\\\n",
      "dataset & model &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{9}{*}{7-scenes} & sift & 0.59 & 0.44 & 0.34 & 0.30 & 0.43 & 0.50 & 0.42 & 0.38 & 0.21 & 0.39 & 0.72 & 0.56 & 0.46 & 0.42 & 0.56 & 0.61 & 0.53 & 0.50 & 0.29 & 0.51 \\\\\n",
      " & loftr & 0.95 & 0.95 & 0.92 & 0.76 & 0.91 & 0.95 & 0.95 & 0.90 & 0.79 & 0.91 & 0.97 & 0.96 & 0.95 & 0.82 & 0.93 & 0.97 & 0.96 & 0.93 & 0.85 & 0.93 \\\\\n",
      " & SpaceQwen2.5-VL-3B-Instruct & 0.63 & 0.60 & 0.60 & 0.61 & 0.61 & 0.40 & 0.47 & 0.43 & 0.45 & 0.44 & 0.62 & 0.60 & 0.60 & 0.59 & 0.60 & 0.41 & 0.47 & 0.44 & 0.45 & 0.44 \\\\\n",
      " & Idefics3-8B-Llama3 & 0.60 & 0.57 & 0.55 & 0.55 & 0.57 & 0.50 & 0.45 & 0.48 & 0.42 & 0.47 & 0.60 & 0.57 & 0.55 & 0.55 & 0.57 & 0.49 & 0.45 & 0.49 & 0.41 & 0.46 \\\\\n",
      " & llava-onevision-qwen2-7b-ov-hf & 0.55 & 0.52 & 0.57 & 0.58 & 0.55 & 0.40 & 0.48 & 0.43 & 0.42 & 0.44 & 0.55 & 0.52 & 0.57 & 0.58 & 0.55 & 0.41 & 0.49 & 0.44 & 0.42 & 0.44 \\\\\n",
      " & Qwen2.5-VL-7B-Instruct & 0.45 & 0.38 & 0.43 & 0.55 & 0.44 & 0.57 & 0.55 & 0.58 & 0.45 & 0.55 & 0.32 & 0.26 & 0.31 & 0.43 & 0.32 & 0.48 & 0.46 & 0.55 & 0.32 & 0.47 \\\\\n",
      " & Qwen2.5-VL-32B-Instruct & 0.45 & 0.45 & 0.47 & 0.50 & 0.46 & 0.67 & 0.57 & 0.47 & 0.34 & 0.53 & 0.44 & 0.46 & 0.47 & 0.51 & 0.46 & 0.66 & 0.56 & 0.48 & 0.34 & 0.53 \\\\\n",
      " & Qwen2.5-VL-72B-Instruct & 0.58 & 0.48 & 0.45 & 0.47 & 0.50 & 0.62 & 0.50 & 0.53 & 0.42 & 0.53 & 0.57 & 0.48 & 0.45 & 0.47 & 0.49 & 0.62 & 0.50 & 0.54 & 0.42 & 0.53 \\\\\n",
      " & gpt-4o & 0.62 & 0.37 & 0.60 & 0.50 & 0.52 & 0.65 & 0.58 & 0.45 & 0.34 & 0.52 & 0.62 & 0.37 & 0.59 & 0.48 & 0.52 & 0.65 & 0.58 & 0.45 & 0.35 & 0.53 \\\\\n",
      "\\cline{1-22}\n",
      "\\multirow[t]{9}{*}{scannet} & sift & 0.18 & 0.17 & 0.15 & 0.11 & 0.15 & 0.22 & 0.20 & 0.12 & 0.15 & 0.18 & 0.28 & 0.27 & 0.23 & 0.18 & 0.24 & 0.33 & 0.31 & 0.18 & 0.24 & 0.28 \\\\\n",
      " & loftr & 0.95 & 0.77 & 0.69 & 0.55 & 0.75 & 0.93 & 0.77 & 0.78 & 0.53 & 0.75 & 0.96 & 0.81 & 0.76 & 0.67 & 0.81 & 0.94 & 0.81 & 0.85 & 0.65 & 0.82 \\\\\n",
      " & SpaceQwen2.5-VL-3B-Instruct & 0.63 & 0.55 & 0.57 & 0.57 & 0.58 & 0.43 & 0.53 & 0.55 & 0.48 & 0.50 & 0.63 & 0.54 & 0.56 & 0.54 & 0.57 & 0.45 & 0.54 & 0.56 & 0.49 & 0.51 \\\\\n",
      " & Idefics3-8B-Llama3 & 0.52 & 0.47 & 0.45 & 0.45 & 0.47 & 0.48 & 0.53 & 0.53 & 0.40 & 0.49 & 0.53 & 0.47 & 0.46 & 0.45 & 0.48 & 0.49 & 0.54 & 0.54 & 0.41 & 0.49 \\\\\n",
      " & llava-onevision-qwen2-7b-ov-hf & 0.55 & 0.45 & 0.45 & 0.53 & 0.50 & 0.43 & 0.53 & 0.53 & 0.47 & 0.49 & 0.57 & 0.46 & 0.46 & 0.54 & 0.50 & 0.45 & 0.54 & 0.54 & 0.47 & 0.50 \\\\\n",
      " & Qwen2.5-VL-7B-Instruct & 0.33 & 0.45 & 0.53 & 0.40 & 0.42 & 0.63 & 0.52 & 0.42 & 0.58 & 0.55 & 0.23 & 0.37 & 0.44 & 0.31 & 0.32 & 0.56 & 0.43 & 0.37 & 0.52 & 0.48 \\\\\n",
      " & Qwen2.5-VL-32B-Instruct & 0.42 & 0.38 & 0.38 & 0.47 & 0.41 & 0.52 & 0.58 & 0.53 & 0.53 & 0.54 & 0.42 & 0.37 & 0.34 & 0.42 & 0.39 & 0.51 & 0.56 & 0.52 & 0.51 & 0.52 \\\\\n",
      " & Qwen2.5-VL-72B-Instruct & 0.40 & 0.40 & 0.43 & 0.45 & 0.42 & 0.60 & 0.62 & 0.62 & 0.53 & 0.59 & 0.38 & 0.40 & 0.41 & 0.40 & 0.40 & 0.61 & 0.62 & 0.61 & 0.54 & 0.60 \\\\\n",
      " & gpt-4o & 0.42 & 0.53 & 0.47 & 0.52 & 0.49 & 0.58 & 0.48 & 0.47 & 0.48 & 0.51 & 0.44 & 0.52 & 0.48 & 0.52 & 0.49 & 0.59 & 0.48 & 0.47 & 0.49 & 0.51 \\\\\n",
      "\\cline{1-22}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output.to_latex(\n",
    "    column_format=\"ll\" + \"c\" * len(output.columns),\n",
    "    float_format=\"%.2f\",\n",
    "    label=\"tab:c2_results\",\n",
    "    caption=\"Results of C2 task with different models, evaluation metrics, and tau values.\",\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b3d4ac",
   "metadata": {},
   "source": [
    "## How about Trap Option?\n",
    "\n",
    "Since both C1 and C2 dataset have 2 setup, but we combinate this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "08fcd478",
   "metadata": {},
   "outputs": [],
   "source": [
    "trap_table = big_table.copy()\n",
    "\n",
    "trap_table = trap_table[~trap_table[\"model\"].isin([\"sift\", \"loftr\"])]\n",
    "trap_table = trap_table[(trap_table[\"prompt_level\"] == \"zero-shot\") | (trap_table[\"prompt_level\"].isna())]\n",
    "\n",
    "model_list_trap = [model for model in model_list if model not in [\"sift\", \"loftr\"]]\n",
    "trap_table[\"model\"] = pd.Categorical(trap_table[\"model\"], categories=model_list_trap, ordered=True)\n",
    "trap_table[\"is_trap\"] = pd.Categorical(trap_table[\"is_trap\"], categories=[False, True], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f20fd5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/user/1483801110/ipykernel_218062/1041263776.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  trap_table = trap_table.groupby([\"task\", \"model\", \"is_trap\"]).apply(compute_metrics).reset_index().pivot(index=[\"task\", \"model\"], columns=\"is_trap\", values=[\"acc\", \"f1\"])\n",
      "/local/user/1483801110/ipykernel_218062/1041263776.py:1: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  trap_table = trap_table.groupby([\"task\", \"model\", \"is_trap\"]).apply(compute_metrics).reset_index().pivot(index=[\"task\", \"model\"], columns=\"is_trap\", values=[\"acc\", \"f1\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>is_trap</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">c1</th>\n",
       "      <th>SpaceQwen2.5-VL-3B-Instruct</th>\n",
       "      <td>0.501479</td>\n",
       "      <td>0.071006</td>\n",
       "      <td>0.503007</td>\n",
       "      <td>0.121841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idefics3-8B-Llama3</th>\n",
       "      <td>0.498521</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.502368</td>\n",
       "      <td>0.342608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava-onevision-qwen2-7b-ov-hf</th>\n",
       "      <td>0.541420</td>\n",
       "      <td>0.110947</td>\n",
       "      <td>0.452324</td>\n",
       "      <td>0.165449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-7B-Instruct</th>\n",
       "      <td>0.670118</td>\n",
       "      <td>0.215976</td>\n",
       "      <td>0.648192</td>\n",
       "      <td>0.299978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-32B-Instruct</th>\n",
       "      <td>0.774123</td>\n",
       "      <td>0.448718</td>\n",
       "      <td>0.765405</td>\n",
       "      <td>0.561254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-72B-Instruct</th>\n",
       "      <td>0.834718</td>\n",
       "      <td>0.783956</td>\n",
       "      <td>0.849372</td>\n",
       "      <td>0.827607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.739645</td>\n",
       "      <td>0.809948</td>\n",
       "      <td>0.748586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">c2</th>\n",
       "      <th>SpaceQwen2.5-VL-3B-Instruct</th>\n",
       "      <td>0.531659</td>\n",
       "      <td>0.253275</td>\n",
       "      <td>0.529887</td>\n",
       "      <td>0.333910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idefics3-8B-Llama3</th>\n",
       "      <td>0.497817</td>\n",
       "      <td>0.359170</td>\n",
       "      <td>0.500809</td>\n",
       "      <td>0.423724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava-onevision-qwen2-7b-ov-hf</th>\n",
       "      <td>0.493450</td>\n",
       "      <td>0.272926</td>\n",
       "      <td>0.498041</td>\n",
       "      <td>0.331924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-7B-Instruct</th>\n",
       "      <td>0.489631</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.397714</td>\n",
       "      <td>0.404246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-32B-Instruct</th>\n",
       "      <td>0.485808</td>\n",
       "      <td>0.321701</td>\n",
       "      <td>0.477512</td>\n",
       "      <td>0.376240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-72B-Instruct</th>\n",
       "      <td>0.509825</td>\n",
       "      <td>0.497817</td>\n",
       "      <td>0.504708</td>\n",
       "      <td>0.494589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.510369</td>\n",
       "      <td>0.523041</td>\n",
       "      <td>0.512641</td>\n",
       "      <td>0.521844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          acc                  f1          \n",
       "is_trap                                 False      True     False      True\n",
       "task model                                                                 \n",
       "c1   SpaceQwen2.5-VL-3B-Instruct     0.501479  0.071006  0.503007  0.121841\n",
       "     Idefics3-8B-Llama3              0.498521  0.250000  0.502368  0.342608\n",
       "     llava-onevision-qwen2-7b-ov-hf  0.541420  0.110947  0.452324  0.165449\n",
       "     Qwen2.5-VL-7B-Instruct          0.670118  0.215976  0.648192  0.299978\n",
       "     Qwen2.5-VL-32B-Instruct         0.774123  0.448718  0.765405  0.561254\n",
       "     Qwen2.5-VL-72B-Instruct         0.834718  0.783956  0.849372  0.827607\n",
       "     gpt-4o                          0.807692  0.739645  0.809948  0.748586\n",
       "c2   SpaceQwen2.5-VL-3B-Instruct     0.531659  0.253275  0.529887  0.333910\n",
       "     Idefics3-8B-Llama3              0.497817  0.359170  0.500809  0.423724\n",
       "     llava-onevision-qwen2-7b-ov-hf  0.493450  0.272926  0.498041  0.331924\n",
       "     Qwen2.5-VL-7B-Instruct          0.489631  0.403226  0.397714  0.404246\n",
       "     Qwen2.5-VL-32B-Instruct         0.485808  0.321701  0.477512  0.376240\n",
       "     Qwen2.5-VL-72B-Instruct         0.509825  0.497817  0.504708  0.494589\n",
       "     gpt-4o                          0.510369  0.523041  0.512641  0.521844"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trap_table = trap_table.groupby([\"task\", \"model\", \"is_trap\"]).apply(compute_metrics).reset_index().pivot(index=[\"task\", \"model\"], columns=\"is_trap\", values=[\"acc\", \"f1\"])\n",
    "trap_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "32f0461e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      " &  & \\multicolumn{2}{r}{acc} & \\multicolumn{2}{r}{f1} \\\\\n",
      " & is_trap & False & True & False & True \\\\\n",
      "task & model &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{7}{*}{c1} & SpaceQwen2.5-VL-3B-Instruct & 0.50 & 0.07 & 0.50 & 0.12 \\\\\n",
      " & Idefics3-8B-Llama3 & 0.50 & 0.25 & 0.50 & 0.34 \\\\\n",
      " & llava-onevision-qwen2-7b-ov-hf & 0.54 & 0.11 & 0.45 & 0.17 \\\\\n",
      " & Qwen2.5-VL-7B-Instruct & 0.67 & 0.22 & 0.65 & 0.30 \\\\\n",
      " & Qwen2.5-VL-32B-Instruct & 0.77 & 0.45 & 0.77 & 0.56 \\\\\n",
      " & Qwen2.5-VL-72B-Instruct & 0.83 & 0.78 & 0.85 & 0.83 \\\\\n",
      " & gpt-4o & 0.81 & 0.74 & 0.81 & 0.75 \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow[t]{7}{*}{c2} & SpaceQwen2.5-VL-3B-Instruct & 0.53 & 0.25 & 0.53 & 0.33 \\\\\n",
      " & Idefics3-8B-Llama3 & 0.50 & 0.36 & 0.50 & 0.42 \\\\\n",
      " & llava-onevision-qwen2-7b-ov-hf & 0.49 & 0.27 & 0.50 & 0.33 \\\\\n",
      " & Qwen2.5-VL-7B-Instruct & 0.49 & 0.40 & 0.40 & 0.40 \\\\\n",
      " & Qwen2.5-VL-32B-Instruct & 0.49 & 0.32 & 0.48 & 0.38 \\\\\n",
      " & Qwen2.5-VL-72B-Instruct & 0.51 & 0.50 & 0.50 & 0.49 \\\\\n",
      " & gpt-4o & 0.51 & 0.52 & 0.51 & 0.52 \\\\\n",
      "\\cline{1-6}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(trap_table.to_latex(\n",
    "    float_format=\"%.2f\",\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cdbcf2",
   "metadata": {},
   "source": [
    "## How about Prompt Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a24dd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_table = c1_df.copy()\n",
    "\n",
    "prompt_table = prompt_table[~prompt_table[\"model\"].isin([\"sift\", \"loftr\"])]\n",
    "prompt_table[\"model\"] = pd.Categorical(prompt_table[\"model\"], categories=model_list_trap, ordered=True)\n",
    "prompt_table[\"prompt_level\"] = pd.Categorical(prompt_table[\"prompt_level\"], categories=[\n",
    "    \"zero-shot\", \n",
    "    \"dataset-prior-hint\",\n",
    "    \"CoT-hint\",\n",
    "    \"VoT-hint\",\n",
    "], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "478c4f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/user/1483801110/ipykernel_218062/1312274158.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  prompt_table = prompt_table.groupby([\"model\", \"prompt_level\"]).apply(compute_metrics).pivot_table(index=\"model\", columns=\"prompt_level\", values=[\"acc\", \"f1\"], observed=True)\n",
      "/local/user/1483801110/ipykernel_218062/1312274158.py:1: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  prompt_table = prompt_table.groupby([\"model\", \"prompt_level\"]).apply(compute_metrics).pivot_table(index=\"model\", columns=\"prompt_level\", values=[\"acc\", \"f1\"], observed=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_level</th>\n",
       "      <th>zero-shot</th>\n",
       "      <th>dataset-prior-hint</th>\n",
       "      <th>CoT-hint</th>\n",
       "      <th>VoT-hint</th>\n",
       "      <th>zero-shot</th>\n",
       "      <th>dataset-prior-hint</th>\n",
       "      <th>CoT-hint</th>\n",
       "      <th>VoT-hint</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SpaceQwen2.5-VL-3B-Instruct</th>\n",
       "      <td>0.286243</td>\n",
       "      <td>0.392012</td>\n",
       "      <td>0.409024</td>\n",
       "      <td>0.422337</td>\n",
       "      <td>0.365161</td>\n",
       "      <td>0.430792</td>\n",
       "      <td>0.434801</td>\n",
       "      <td>0.441852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idefics3-8B-Llama3</th>\n",
       "      <td>0.374260</td>\n",
       "      <td>0.474112</td>\n",
       "      <td>0.504438</td>\n",
       "      <td>0.469675</td>\n",
       "      <td>0.436002</td>\n",
       "      <td>0.488488</td>\n",
       "      <td>0.512551</td>\n",
       "      <td>0.450233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava-onevision-qwen2-7b-ov-hf</th>\n",
       "      <td>0.326183</td>\n",
       "      <td>0.464497</td>\n",
       "      <td>0.438609</td>\n",
       "      <td>0.468935</td>\n",
       "      <td>0.351719</td>\n",
       "      <td>0.440272</td>\n",
       "      <td>0.443518</td>\n",
       "      <td>0.431512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-7B-Instruct</th>\n",
       "      <td>0.443047</td>\n",
       "      <td>0.602811</td>\n",
       "      <td>0.457840</td>\n",
       "      <td>0.477071</td>\n",
       "      <td>0.512270</td>\n",
       "      <td>0.579210</td>\n",
       "      <td>0.384622</td>\n",
       "      <td>0.436887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-32B-Instruct</th>\n",
       "      <td>0.596806</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.644904</td>\n",
       "      <td>0.690355</td>\n",
       "      <td>0.670075</td>\n",
       "      <td>0.752911</td>\n",
       "      <td>0.664250</td>\n",
       "      <td>0.710102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-VL-72B-Instruct</th>\n",
       "      <td>0.808770</td>\n",
       "      <td>0.801184</td>\n",
       "      <td>0.589391</td>\n",
       "      <td>0.654124</td>\n",
       "      <td>0.839160</td>\n",
       "      <td>0.803365</td>\n",
       "      <td>0.574388</td>\n",
       "      <td>0.649181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.773669</td>\n",
       "      <td>0.743343</td>\n",
       "      <td>0.551775</td>\n",
       "      <td>0.486686</td>\n",
       "      <td>0.779820</td>\n",
       "      <td>0.738757</td>\n",
       "      <td>0.539478</td>\n",
       "      <td>0.472663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     acc                               \\\n",
       "prompt_level                   zero-shot dataset-prior-hint  CoT-hint   \n",
       "model                                                                   \n",
       "SpaceQwen2.5-VL-3B-Instruct     0.286243           0.392012  0.409024   \n",
       "Idefics3-8B-Llama3              0.374260           0.474112  0.504438   \n",
       "llava-onevision-qwen2-7b-ov-hf  0.326183           0.464497  0.438609   \n",
       "Qwen2.5-VL-7B-Instruct          0.443047           0.602811  0.457840   \n",
       "Qwen2.5-VL-32B-Instruct         0.596806           0.738487  0.644904   \n",
       "Qwen2.5-VL-72B-Instruct         0.808770           0.801184  0.589391   \n",
       "gpt-4o                          0.773669           0.743343  0.551775   \n",
       "\n",
       "                                                f1                     \\\n",
       "prompt_level                    VoT-hint zero-shot dataset-prior-hint   \n",
       "model                                                                   \n",
       "SpaceQwen2.5-VL-3B-Instruct     0.422337  0.365161           0.430792   \n",
       "Idefics3-8B-Llama3              0.469675  0.436002           0.488488   \n",
       "llava-onevision-qwen2-7b-ov-hf  0.468935  0.351719           0.440272   \n",
       "Qwen2.5-VL-7B-Instruct          0.477071  0.512270           0.579210   \n",
       "Qwen2.5-VL-32B-Instruct         0.690355  0.670075           0.752911   \n",
       "Qwen2.5-VL-72B-Instruct         0.654124  0.839160           0.803365   \n",
       "gpt-4o                          0.486686  0.779820           0.738757   \n",
       "\n",
       "                                                    \n",
       "prompt_level                    CoT-hint  VoT-hint  \n",
       "model                                               \n",
       "SpaceQwen2.5-VL-3B-Instruct     0.434801  0.441852  \n",
       "Idefics3-8B-Llama3              0.512551  0.450233  \n",
       "llava-onevision-qwen2-7b-ov-hf  0.443518  0.431512  \n",
       "Qwen2.5-VL-7B-Instruct          0.384622  0.436887  \n",
       "Qwen2.5-VL-32B-Instruct         0.664250  0.710102  \n",
       "Qwen2.5-VL-72B-Instruct         0.574388  0.649181  \n",
       "gpt-4o                          0.539478  0.472663  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_table = prompt_table.groupby([\"model\", \"prompt_level\"]).apply(compute_metrics).pivot_table(index=\"model\", columns=\"prompt_level\", values=[\"acc\", \"f1\"], observed=True)\n",
    "prompt_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fa4ed9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      " & \\multicolumn{4}{r}{acc} & \\multicolumn{4}{r}{f1} \\\\\n",
      "prompt_level & zero-shot & dataset-prior-hint & CoT-hint & VoT-hint & zero-shot & dataset-prior-hint & CoT-hint & VoT-hint \\\\\n",
      "model &  &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "SpaceQwen2.5-VL-3B-Instruct & 0.29 & 0.39 & 0.41 & 0.42 & 0.37 & 0.43 & 0.43 & 0.44 \\\\\n",
      "Idefics3-8B-Llama3 & 0.37 & 0.47 & 0.50 & 0.47 & 0.44 & 0.49 & 0.51 & 0.45 \\\\\n",
      "llava-onevision-qwen2-7b-ov-hf & 0.33 & 0.46 & 0.44 & 0.47 & 0.35 & 0.44 & 0.44 & 0.43 \\\\\n",
      "Qwen2.5-VL-7B-Instruct & 0.44 & 0.60 & 0.46 & 0.48 & 0.51 & 0.58 & 0.38 & 0.44 \\\\\n",
      "Qwen2.5-VL-32B-Instruct & 0.60 & 0.74 & 0.64 & 0.69 & 0.67 & 0.75 & 0.66 & 0.71 \\\\\n",
      "Qwen2.5-VL-72B-Instruct & 0.81 & 0.80 & 0.59 & 0.65 & 0.84 & 0.80 & 0.57 & 0.65 \\\\\n",
      "gpt-4o & 0.77 & 0.74 & 0.55 & 0.49 & 0.78 & 0.74 & 0.54 & 0.47 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_table.to_latex(\n",
    "    float_format=\"%.2f\",\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02264585",
   "metadata": {},
   "source": [
    "## Let's See a Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2420bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "trap_table = c1_df.copy()\n",
    "\n",
    "trap_table = trap_table[~trap_table[\"model\"].isin([\"sift\", \"loftr\"])]\n",
    "# trap_table = trap_table[trap_table[\"prompt_level\"] == \"zero-shot\"]\n",
    "model_list_trap = [model for model in model_list if model not in [\"sift\", \"loftr\"]]\n",
    "trap_table[\"model\"] = pd.Categorical(trap_table[\"model\"], categories=model_list_trap, ordered=True)\n",
    "trap_table[\"prompt_level\"] = pd.Categorical(trap_table[\"prompt_level\"], categories=[\n",
    "    \"zero-shot\", \n",
    "    \"dataset-prior-hint\",\n",
    "    \"CoT-hint\",\n",
    "    \"VoT-hint\",\n",
    "], ordered=True)\n",
    "trap_table[\"is_trap\"] = pd.Categorical(trap_table[\"is_trap\"], categories=[True, False], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "14ba38c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/user/1483801110/ipykernel_218062/2832700779.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  trap_table = trap_table.groupby([\"model\", \"prompt_level\", \"is_trap\"]).apply(compute_metrics).reset_index().pivot(index=[\"model\", \"is_trap\"], columns=[\"prompt_level\"], values=[\"acc\", \"f1\"])\n",
      "/local/user/1483801110/ipykernel_218062/2832700779.py:1: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  trap_table = trap_table.groupby([\"model\", \"prompt_level\", \"is_trap\"]).apply(compute_metrics).reset_index().pivot(index=[\"model\", \"is_trap\"], columns=[\"prompt_level\"], values=[\"acc\", \"f1\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>prompt_level</th>\n",
       "      <th>zero-shot</th>\n",
       "      <th>dataset-prior-hint</th>\n",
       "      <th>CoT-hint</th>\n",
       "      <th>VoT-hint</th>\n",
       "      <th>zero-shot</th>\n",
       "      <th>dataset-prior-hint</th>\n",
       "      <th>CoT-hint</th>\n",
       "      <th>VoT-hint</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>is_trap</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SpaceQwen2.5-VL-3B-Instruct</th>\n",
       "      <th>True</th>\n",
       "      <td>0.071006</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.315089</td>\n",
       "      <td>0.319527</td>\n",
       "      <td>0.121841</td>\n",
       "      <td>0.366036</td>\n",
       "      <td>0.373071</td>\n",
       "      <td>0.376624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.501479</td>\n",
       "      <td>0.495562</td>\n",
       "      <td>0.502959</td>\n",
       "      <td>0.525148</td>\n",
       "      <td>0.503007</td>\n",
       "      <td>0.475364</td>\n",
       "      <td>0.481015</td>\n",
       "      <td>0.492853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Idefics3-8B-Llama3</th>\n",
       "      <th>True</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.439349</td>\n",
       "      <td>0.473373</td>\n",
       "      <td>0.471893</td>\n",
       "      <td>0.342608</td>\n",
       "      <td>0.468821</td>\n",
       "      <td>0.489697</td>\n",
       "      <td>0.449636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.498521</td>\n",
       "      <td>0.508876</td>\n",
       "      <td>0.535503</td>\n",
       "      <td>0.467456</td>\n",
       "      <td>0.502368</td>\n",
       "      <td>0.504518</td>\n",
       "      <td>0.532508</td>\n",
       "      <td>0.445257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">llava-onevision-qwen2-7b-ov-hf</th>\n",
       "      <th>True</th>\n",
       "      <td>0.110947</td>\n",
       "      <td>0.439349</td>\n",
       "      <td>0.396450</td>\n",
       "      <td>0.448225</td>\n",
       "      <td>0.165449</td>\n",
       "      <td>0.448105</td>\n",
       "      <td>0.422171</td>\n",
       "      <td>0.445837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.541420</td>\n",
       "      <td>0.489645</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.489645</td>\n",
       "      <td>0.452324</td>\n",
       "      <td>0.423257</td>\n",
       "      <td>0.437251</td>\n",
       "      <td>0.408460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Qwen2.5-VL-7B-Instruct</th>\n",
       "      <th>True</th>\n",
       "      <td>0.215976</td>\n",
       "      <td>0.560651</td>\n",
       "      <td>0.452663</td>\n",
       "      <td>0.465976</td>\n",
       "      <td>0.299978</td>\n",
       "      <td>0.539490</td>\n",
       "      <td>0.389269</td>\n",
       "      <td>0.415296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.670118</td>\n",
       "      <td>0.644970</td>\n",
       "      <td>0.463018</td>\n",
       "      <td>0.488166</td>\n",
       "      <td>0.648192</td>\n",
       "      <td>0.614073</td>\n",
       "      <td>0.374323</td>\n",
       "      <td>0.445790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Qwen2.5-VL-32B-Instruct</th>\n",
       "      <th>True</th>\n",
       "      <td>0.448718</td>\n",
       "      <td>0.709430</td>\n",
       "      <td>0.619342</td>\n",
       "      <td>0.637516</td>\n",
       "      <td>0.561254</td>\n",
       "      <td>0.741330</td>\n",
       "      <td>0.653401</td>\n",
       "      <td>0.674561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.774123</td>\n",
       "      <td>0.767544</td>\n",
       "      <td>0.672149</td>\n",
       "      <td>0.743329</td>\n",
       "      <td>0.765405</td>\n",
       "      <td>0.762493</td>\n",
       "      <td>0.670409</td>\n",
       "      <td>0.741434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Qwen2.5-VL-72B-Instruct</th>\n",
       "      <th>True</th>\n",
       "      <td>0.783956</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.613553</td>\n",
       "      <td>0.668322</td>\n",
       "      <td>0.827607</td>\n",
       "      <td>0.802484</td>\n",
       "      <td>0.608908</td>\n",
       "      <td>0.665094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.834718</td>\n",
       "      <td>0.808556</td>\n",
       "      <td>0.561441</td>\n",
       "      <td>0.638800</td>\n",
       "      <td>0.849372</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.527600</td>\n",
       "      <td>0.630358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gpt-4o</th>\n",
       "      <th>True</th>\n",
       "      <td>0.739645</td>\n",
       "      <td>0.726331</td>\n",
       "      <td>0.526627</td>\n",
       "      <td>0.476331</td>\n",
       "      <td>0.748586</td>\n",
       "      <td>0.718515</td>\n",
       "      <td>0.520164</td>\n",
       "      <td>0.461981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760355</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.497041</td>\n",
       "      <td>0.809948</td>\n",
       "      <td>0.757918</td>\n",
       "      <td>0.551408</td>\n",
       "      <td>0.482850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             acc                               \\\n",
       "prompt_level                           zero-shot dataset-prior-hint  CoT-hint   \n",
       "model                          is_trap                                          \n",
       "SpaceQwen2.5-VL-3B-Instruct    True     0.071006           0.288462  0.315089   \n",
       "                               False    0.501479           0.495562  0.502959   \n",
       "Idefics3-8B-Llama3             True     0.250000           0.439349  0.473373   \n",
       "                               False    0.498521           0.508876  0.535503   \n",
       "llava-onevision-qwen2-7b-ov-hf True     0.110947           0.439349  0.396450   \n",
       "                               False    0.541420           0.489645  0.480769   \n",
       "Qwen2.5-VL-7B-Instruct         True     0.215976           0.560651  0.452663   \n",
       "                               False    0.670118           0.644970  0.463018   \n",
       "Qwen2.5-VL-32B-Instruct        True     0.448718           0.709430  0.619342   \n",
       "                               False    0.774123           0.767544  0.672149   \n",
       "Qwen2.5-VL-72B-Instruct        True     0.783956           0.794872  0.613553   \n",
       "                               False    0.834718           0.808556  0.561441   \n",
       "gpt-4o                         True     0.739645           0.726331  0.526627   \n",
       "                               False    0.807692           0.760355  0.576923   \n",
       "\n",
       "                                                        f1                     \\\n",
       "prompt_level                            VoT-hint zero-shot dataset-prior-hint   \n",
       "model                          is_trap                                          \n",
       "SpaceQwen2.5-VL-3B-Instruct    True     0.319527  0.121841           0.366036   \n",
       "                               False    0.525148  0.503007           0.475364   \n",
       "Idefics3-8B-Llama3             True     0.471893  0.342608           0.468821   \n",
       "                               False    0.467456  0.502368           0.504518   \n",
       "llava-onevision-qwen2-7b-ov-hf True     0.448225  0.165449           0.448105   \n",
       "                               False    0.489645  0.452324           0.423257   \n",
       "Qwen2.5-VL-7B-Instruct         True     0.465976  0.299978           0.539490   \n",
       "                               False    0.488166  0.648192           0.614073   \n",
       "Qwen2.5-VL-32B-Instruct        True     0.637516  0.561254           0.741330   \n",
       "                               False    0.743329  0.765405           0.762493   \n",
       "Qwen2.5-VL-72B-Instruct        True     0.668322  0.827607           0.802484   \n",
       "                               False    0.638800  0.849372           0.803167   \n",
       "gpt-4o                         True     0.476331  0.748586           0.718515   \n",
       "                               False    0.497041  0.809948           0.757918   \n",
       "\n",
       "                                                            \n",
       "prompt_level                            CoT-hint  VoT-hint  \n",
       "model                          is_trap                      \n",
       "SpaceQwen2.5-VL-3B-Instruct    True     0.373071  0.376624  \n",
       "                               False    0.481015  0.492853  \n",
       "Idefics3-8B-Llama3             True     0.489697  0.449636  \n",
       "                               False    0.532508  0.445257  \n",
       "llava-onevision-qwen2-7b-ov-hf True     0.422171  0.445837  \n",
       "                               False    0.437251  0.408460  \n",
       "Qwen2.5-VL-7B-Instruct         True     0.389269  0.415296  \n",
       "                               False    0.374323  0.445790  \n",
       "Qwen2.5-VL-32B-Instruct        True     0.653401  0.674561  \n",
       "                               False    0.670409  0.741434  \n",
       "Qwen2.5-VL-72B-Instruct        True     0.608908  0.665094  \n",
       "                               False    0.527600  0.630358  \n",
       "gpt-4o                         True     0.520164  0.461981  \n",
       "                               False    0.551408  0.482850  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trap_table = trap_table.groupby([\"model\", \"prompt_level\", \"is_trap\"]).apply(compute_metrics).reset_index().pivot(index=[\"model\", \"is_trap\"], columns=[\"prompt_level\"], values=[\"acc\", \"f1\"])\n",
    "trap_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5d65a700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrrrr}\n",
      "\\toprule\n",
      " &  & \\multicolumn{4}{r}{acc} & \\multicolumn{4}{r}{f1} \\\\\n",
      " & prompt_level & zero-shot & dataset-prior-hint & CoT-hint & VoT-hint & zero-shot & dataset-prior-hint & CoT-hint & VoT-hint \\\\\n",
      "model & is_trap &  &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{2}{*}{SpaceQwen2.5-VL-3B-Instruct} & True & 0.07 & 0.29 & 0.32 & 0.32 & 0.12 & 0.37 & 0.37 & 0.38 \\\\\n",
      " & False & 0.50 & 0.50 & 0.50 & 0.53 & 0.50 & 0.48 & 0.48 & 0.49 \\\\\n",
      "\\cline{1-10}\n",
      "\\multirow[t]{2}{*}{Idefics3-8B-Llama3} & True & 0.25 & 0.44 & 0.47 & 0.47 & 0.34 & 0.47 & 0.49 & 0.45 \\\\\n",
      " & False & 0.50 & 0.51 & 0.54 & 0.47 & 0.50 & 0.50 & 0.53 & 0.45 \\\\\n",
      "\\cline{1-10}\n",
      "\\multirow[t]{2}{*}{llava-onevision-qwen2-7b-ov-hf} & True & 0.11 & 0.44 & 0.40 & 0.45 & 0.17 & 0.45 & 0.42 & 0.45 \\\\\n",
      " & False & 0.54 & 0.49 & 0.48 & 0.49 & 0.45 & 0.42 & 0.44 & 0.41 \\\\\n",
      "\\cline{1-10}\n",
      "\\multirow[t]{2}{*}{Qwen2.5-VL-7B-Instruct} & True & 0.22 & 0.56 & 0.45 & 0.47 & 0.30 & 0.54 & 0.39 & 0.42 \\\\\n",
      " & False & 0.67 & 0.64 & 0.46 & 0.49 & 0.65 & 0.61 & 0.37 & 0.45 \\\\\n",
      "\\cline{1-10}\n",
      "\\multirow[t]{2}{*}{Qwen2.5-VL-32B-Instruct} & True & 0.45 & 0.71 & 0.62 & 0.64 & 0.56 & 0.74 & 0.65 & 0.67 \\\\\n",
      " & False & 0.77 & 0.77 & 0.67 & 0.74 & 0.77 & 0.76 & 0.67 & 0.74 \\\\\n",
      "\\cline{1-10}\n",
      "\\multirow[t]{2}{*}{Qwen2.5-VL-72B-Instruct} & True & 0.78 & 0.79 & 0.61 & 0.67 & 0.83 & 0.80 & 0.61 & 0.67 \\\\\n",
      " & False & 0.83 & 0.81 & 0.56 & 0.64 & 0.85 & 0.80 & 0.53 & 0.63 \\\\\n",
      "\\cline{1-10}\n",
      "\\multirow[t]{2}{*}{gpt-4o} & True & 0.74 & 0.73 & 0.53 & 0.48 & 0.75 & 0.72 & 0.52 & 0.46 \\\\\n",
      " & False & 0.81 & 0.76 & 0.58 & 0.50 & 0.81 & 0.76 & 0.55 & 0.48 \\\\\n",
      "\\cline{1-10}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(trap_table.to_latex(\n",
    "    float_format=\"%.2f\",\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial_reasoning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
