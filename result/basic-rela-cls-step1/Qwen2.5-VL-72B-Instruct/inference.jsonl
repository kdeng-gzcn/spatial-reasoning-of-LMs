{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/psi_significant/fire/seq-03/000950-000970/target/frame-000970.color.png", "cap": ["Fire Extinguisher is on the left of Yellow Sign.", "Fire Extinguisher is on the right of Yellow Sign.", "Fire Extinguisher is above Yellow Sign.", "Fire Extinguisher is below Yellow Sign.", "Fire Extinguisher is in front of Yellow Sign.", "Fire Extinguisher is behind Yellow Sign."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Fire Extinguisher is on the left of Yellow Sign.\n1. Fire Extinguisher is on the right of Yellow Sign.\n2. Fire Extinguisher is above Yellow Sign.\n3. Fire Extinguisher is below Yellow Sign.\n4. Fire Extinguisher is in front of Yellow Sign.\n5. Fire Extinguisher is behind Yellow Sign.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 0, "cor_rela": "left", "cap_shuf": ["Fire Extinguisher is below Yellow Sign.", "Fire Extinguisher is on the left of Yellow Sign.", "Fire Extinguisher is above Yellow Sign.", "Fire Extinguisher is in front of Yellow Sign.", "Fire Extinguisher is behind Yellow Sign.", "Fire Extinguisher is on the right of Yellow Sign."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Fire Extinguisher is below Yellow Sign.\n1. Fire Extinguisher is on the left of Yellow Sign.\n2. Fire Extinguisher is above Yellow Sign.\n3. Fire Extinguisher is in front of Yellow Sign.\n4. Fire Extinguisher is behind Yellow Sign.\n5. Fire Extinguisher is on the right of Yellow Sign.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 1, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 1, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/psi_significant/fire/seq-03/000950-000970/target/frame-000970.color.png", "cap": ["Yellow Sign is on the left of Fire Extinguisher.", "Yellow Sign is on the right of Fire Extinguisher.", "Yellow Sign is above Fire Extinguisher.", "Yellow Sign is below Fire Extinguisher.", "Yellow Sign is in front of Fire Extinguisher.", "Yellow Sign is behind Fire Extinguisher."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Yellow Sign is on the left of Fire Extinguisher.\n1. Yellow Sign is on the right of Fire Extinguisher.\n2. Yellow Sign is above Fire Extinguisher.\n3. Yellow Sign is below Fire Extinguisher.\n4. Yellow Sign is in front of Fire Extinguisher.\n5. Yellow Sign is behind Fire Extinguisher.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 1, "cor_rela": "right", "cap_shuf": ["Yellow Sign is below Fire Extinguisher.", "Yellow Sign is on the right of Fire Extinguisher.", "Yellow Sign is above Fire Extinguisher.", "Yellow Sign is on the left of Fire Extinguisher.", "Yellow Sign is in front of Fire Extinguisher.", "Yellow Sign is behind Fire Extinguisher."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Yellow Sign is below Fire Extinguisher.\n1. Yellow Sign is on the right of Fire Extinguisher.\n2. Yellow Sign is above Fire Extinguisher.\n3. Yellow Sign is on the left of Fire Extinguisher.\n4. Yellow Sign is in front of Fire Extinguisher.\n5. Yellow Sign is behind Fire Extinguisher.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 1, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 1, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/psi_significant/fire/seq-03/000671-000688/target/frame-000688.color.png", "cap": ["Fire Extinguisher is on the left of Plant.", "Fire Extinguisher is on the right of Plant.", "Fire Extinguisher is above Plant.", "Fire Extinguisher is below Plant.", "Fire Extinguisher is in front of Plant.", "Fire Extinguisher is behind Plant."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Fire Extinguisher is on the left of Plant.\n1. Fire Extinguisher is on the right of Plant.\n2. Fire Extinguisher is above Plant.\n3. Fire Extinguisher is below Plant.\n4. Fire Extinguisher is in front of Plant.\n5. Fire Extinguisher is behind Plant.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 0, "cor_rela": "left", "cap_shuf": ["Fire Extinguisher is on the right of Plant.", "Fire Extinguisher is above Plant.", "Fire Extinguisher is below Plant.", "Fire Extinguisher is in front of Plant.", "Fire Extinguisher is behind Plant.", "Fire Extinguisher is on the left of Plant."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Fire Extinguisher is on the right of Plant.\n1. Fire Extinguisher is above Plant.\n2. Fire Extinguisher is below Plant.\n3. Fire Extinguisher is in front of Plant.\n4. Fire Extinguisher is behind Plant.\n5. Fire Extinguisher is on the left of Plant.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 5, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 5, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/psi_significant/fire/seq-03/000671-000688/target/frame-000688.color.png", "cap": ["Plant is on the left of Fire Extinguisher.", "Plant is on the right of Fire Extinguisher.", "Plant is above Fire Extinguisher.", "Plant is below Fire Extinguisher.", "Plant is in front of Fire Extinguisher.", "Plant is behind Fire Extinguisher."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Plant is on the left of Fire Extinguisher.\n1. Plant is on the right of Fire Extinguisher.\n2. Plant is above Fire Extinguisher.\n3. Plant is below Fire Extinguisher.\n4. Plant is in front of Fire Extinguisher.\n5. Plant is behind Fire Extinguisher.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 1, "cor_rela": "right", "cap_shuf": ["Plant is on the right of Fire Extinguisher.", "Plant is below Fire Extinguisher.", "Plant is above Fire Extinguisher.", "Plant is on the left of Fire Extinguisher.", "Plant is behind Fire Extinguisher.", "Plant is in front of Fire Extinguisher."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Plant is on the right of Fire Extinguisher.\n1. Plant is below Fire Extinguisher.\n2. Plant is above Fire Extinguisher.\n3. Plant is on the left of Fire Extinguisher.\n4. Plant is behind Fire Extinguisher.\n5. Plant is in front of Fire Extinguisher.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 0, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 0, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/psi_significant/office/seq-06/000449-000473/target/frame-000473.color.png", "cap": ["Computer is on the left side of the image", "Computer is on the right side of the image", "Computer is on the top of the image", "Computer is on the bottom of the image"], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Computer is on the left side of the image\n1. Computer is on the right side of the image\n2. Computer is on the top of the image\n3. Computer is on the bottom of the image\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 2, "cor_rela": "top", "cap_shuf": ["Computer is on the top of the image", "Computer is on the right side of the image", "Computer is on the left side of the image", "Computer is on the bottom of the image"], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Computer is on the top of the image\n1. Computer is on the right side of the image\n2. Computer is on the left side of the image\n3. Computer is on the bottom of the image\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 0, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 1, "is_correct": false, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/psi_significant/office/seq-06/000449-000473/target/frame-000473.color.png", "cap": ["Computer is on the left of Keyboard.", "Computer is on the right of Keyboard.", "Computer is above Keyboard.", "Computer is below Keyboard.", "Computer is in front of Keyboard.", "Computer is behind Keyboard."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Computer is on the left of Keyboard.\n1. Computer is on the right of Keyboard.\n2. Computer is above Keyboard.\n3. Computer is below Keyboard.\n4. Computer is in front of Keyboard.\n5. Computer is behind Keyboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 5, "cor_rela": "behind", "cap_shuf": ["Computer is behind Keyboard.", "Computer is on the right of Keyboard.", "Computer is below Keyboard.", "Computer is on the left of Keyboard.", "Computer is above Keyboard.", "Computer is in front of Keyboard."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Computer is behind Keyboard.\n1. Computer is on the right of Keyboard.\n2. Computer is below Keyboard.\n3. Computer is on the left of Keyboard.\n4. Computer is above Keyboard.\n5. Computer is in front of Keyboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 0, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 4, "is_correct": false, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/psi_significant/office/seq-06/000449-000473/target/frame-000473.color.png", "cap": ["Keyboard is on the left of Computer.", "Keyboard is on the right of Computer.", "Keyboard is above Computer.", "Keyboard is below Computer.", "Keyboard is in front of Computer.", "Keyboard is behind Computer."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Keyboard is on the left of Computer.\n1. Keyboard is on the right of Computer.\n2. Keyboard is above Computer.\n3. Keyboard is below Computer.\n4. Keyboard is in front of Computer.\n5. Keyboard is behind Computer.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 4, "cor_rela": "front", "cap_shuf": ["Keyboard is above Computer.", "Keyboard is on the right of Computer.", "Keyboard is in front of Computer.", "Keyboard is below Computer.", "Keyboard is behind Computer.", "Keyboard is on the left of Computer."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Keyboard is above Computer.\n1. Keyboard is on the right of Computer.\n2. Keyboard is in front of Computer.\n3. Keyboard is below Computer.\n4. Keyboard is behind Computer.\n5. Keyboard is on the left of Computer.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 2, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 2, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/theta_significant/office/seq-03/000416-000447/target/frame-000447.color.png", "cap": ["Oranges is on the left of Mouse.", "Oranges is on the right of Mouse.", "Oranges is above Mouse.", "Oranges is below Mouse.", "Oranges is in front of Mouse.", "Oranges is behind Mouse."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Oranges is on the left of Mouse.\n1. Oranges is on the right of Mouse.\n2. Oranges is above Mouse.\n3. Oranges is below Mouse.\n4. Oranges is in front of Mouse.\n5. Oranges is behind Mouse.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 0, "cor_rela": "left", "cap_shuf": ["Oranges is below Mouse.", "Oranges is on the right of Mouse.", "Oranges is on the left of Mouse.", "Oranges is behind Mouse.", "Oranges is in front of Mouse.", "Oranges is above Mouse."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Oranges is below Mouse.\n1. Oranges is on the right of Mouse.\n2. Oranges is on the left of Mouse.\n3. Oranges is behind Mouse.\n4. Oranges is in front of Mouse.\n5. Oranges is above Mouse.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 2, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 2, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/theta_significant/office/seq-03/000416-000447/target/frame-000447.color.png", "cap": ["Mouse is on the left of Oranges.", "Mouse is on the right of Oranges.", "Mouse is above Oranges.", "Mouse is below Oranges.", "Mouse is in front of Oranges.", "Mouse is behind Oranges."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Mouse is on the left of Oranges.\n1. Mouse is on the right of Oranges.\n2. Mouse is above Oranges.\n3. Mouse is below Oranges.\n4. Mouse is in front of Oranges.\n5. Mouse is behind Oranges.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 1, "cor_rela": "right", "cap_shuf": ["Mouse is above Oranges.", "Mouse is on the right of Oranges.", "Mouse is behind Oranges.", "Mouse is below Oranges.", "Mouse is on the left of Oranges.", "Mouse is in front of Oranges."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Mouse is above Oranges.\n1. Mouse is on the right of Oranges.\n2. Mouse is behind Oranges.\n3. Mouse is below Oranges.\n4. Mouse is on the left of Oranges.\n5. Mouse is in front of Oranges.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 1, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 1, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/theta_significant/office/seq-03/000256-000272/target/frame-000272.color.png", "cap": ["Shelf is on the left side of the image", "Shelf is on the right side of the image", "Shelf is on the top of the image", "Shelf is on the bottom of the image"], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Shelf is on the left side of the image\n1. Shelf is on the right side of the image\n2. Shelf is on the top of the image\n3. Shelf is on the bottom of the image\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 2, "cor_rela": "top", "cap_shuf": ["Shelf is on the right side of the image", "Shelf is on the left side of the image", "Shelf is on the bottom of the image", "Shelf is on the top of the image"], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Shelf is on the right side of the image\n1. Shelf is on the left side of the image\n2. Shelf is on the bottom of the image\n3. Shelf is on the top of the image\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 3, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 1, "is_correct": false, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/theta_significant/pumpkin/seq-01/000715-000745/target/frame-000745.color.png", "cap": ["Red Wall Cabinet is on the left of Coffee Machine.", "Red Wall Cabinet is on the right of Coffee Machine.", "Red Wall Cabinet is above Coffee Machine.", "Red Wall Cabinet is below Coffee Machine.", "Red Wall Cabinet is in front of Coffee Machine.", "Red Wall Cabinet is behind Coffee Machine."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Red Wall Cabinet is on the left of Coffee Machine.\n1. Red Wall Cabinet is on the right of Coffee Machine.\n2. Red Wall Cabinet is above Coffee Machine.\n3. Red Wall Cabinet is below Coffee Machine.\n4. Red Wall Cabinet is in front of Coffee Machine.\n5. Red Wall Cabinet is behind Coffee Machine.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 0, "cor_rela": "left", "cap_shuf": ["Red Wall Cabinet is on the right of Coffee Machine.", "Red Wall Cabinet is below Coffee Machine.", "Red Wall Cabinet is above Coffee Machine.", "Red Wall Cabinet is in front of Coffee Machine.", "Red Wall Cabinet is on the left of Coffee Machine.", "Red Wall Cabinet is behind Coffee Machine."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Red Wall Cabinet is on the right of Coffee Machine.\n1. Red Wall Cabinet is below Coffee Machine.\n2. Red Wall Cabinet is above Coffee Machine.\n3. Red Wall Cabinet is in front of Coffee Machine.\n4. Red Wall Cabinet is on the left of Coffee Machine.\n5. Red Wall Cabinet is behind Coffee Machine.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 4, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 4, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/theta_significant/pumpkin/seq-01/000715-000745/target/frame-000745.color.png", "cap": ["Coffee Machine is on the left of Red Wall Cabinet.", "Coffee Machine is on the right of Red Wall Cabinet.", "Coffee Machine is above Red Wall Cabinet.", "Coffee Machine is below Red Wall Cabinet.", "Coffee Machine is in front of Red Wall Cabinet.", "Coffee Machine is behind Red Wall Cabinet."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Coffee Machine is on the left of Red Wall Cabinet.\n1. Coffee Machine is on the right of Red Wall Cabinet.\n2. Coffee Machine is above Red Wall Cabinet.\n3. Coffee Machine is below Red Wall Cabinet.\n4. Coffee Machine is in front of Red Wall Cabinet.\n5. Coffee Machine is behind Red Wall Cabinet.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 1, "cor_rela": "right", "cap_shuf": ["Coffee Machine is behind Red Wall Cabinet.", "Coffee Machine is below Red Wall Cabinet.", "Coffee Machine is in front of Red Wall Cabinet.", "Coffee Machine is on the right of Red Wall Cabinet.", "Coffee Machine is on the left of Red Wall Cabinet.", "Coffee Machine is above Red Wall Cabinet."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Coffee Machine is behind Red Wall Cabinet.\n1. Coffee Machine is below Red Wall Cabinet.\n2. Coffee Machine is in front of Red Wall Cabinet.\n3. Coffee Machine is on the right of Red Wall Cabinet.\n4. Coffee Machine is on the left of Red Wall Cabinet.\n5. Coffee Machine is above Red Wall Cabinet.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 3, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 1, "is_correct": false, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/theta_significant/pumpkin/seq-01/000000-000042/target/frame-000042.color.png", "cap": ["Red Cabinet is on the left of Pumpkin.", "Red Cabinet is on the right of Pumpkin.", "Red Cabinet is above Pumpkin.", "Red Cabinet is below Pumpkin.", "Red Cabinet is in front of Pumpkin.", "Red Cabinet is behind Pumpkin."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Red Cabinet is on the left of Pumpkin.\n1. Red Cabinet is on the right of Pumpkin.\n2. Red Cabinet is above Pumpkin.\n3. Red Cabinet is below Pumpkin.\n4. Red Cabinet is in front of Pumpkin.\n5. Red Cabinet is behind Pumpkin.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 5, "cor_rela": "behind", "cap_shuf": ["Red Cabinet is in front of Pumpkin.", "Red Cabinet is on the right of Pumpkin.", "Red Cabinet is on the left of Pumpkin.", "Red Cabinet is behind Pumpkin.", "Red Cabinet is below Pumpkin.", "Red Cabinet is above Pumpkin."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Red Cabinet is in front of Pumpkin.\n1. Red Cabinet is on the right of Pumpkin.\n2. Red Cabinet is on the left of Pumpkin.\n3. Red Cabinet is behind Pumpkin.\n4. Red Cabinet is below Pumpkin.\n5. Red Cabinet is above Pumpkin.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 3, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 3, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/theta_significant/pumpkin/seq-01/000000-000042/target/frame-000042.color.png", "cap": ["Pumpkin is on the left of Red Cabinet.", "Pumpkin is on the right of Red Cabinet.", "Pumpkin is above Red Cabinet.", "Pumpkin is below Red Cabinet.", "Pumpkin is in front of Red Cabinet.", "Pumpkin is behind Red Cabinet."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Pumpkin is on the left of Red Cabinet.\n1. Pumpkin is on the right of Red Cabinet.\n2. Pumpkin is above Red Cabinet.\n3. Pumpkin is below Red Cabinet.\n4. Pumpkin is in front of Red Cabinet.\n5. Pumpkin is behind Red Cabinet.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 4, "cor_rela": "front", "cap_shuf": ["Pumpkin is in front of Red Cabinet.", "Pumpkin is on the left of Red Cabinet.", "Pumpkin is below Red Cabinet.", "Pumpkin is behind Red Cabinet.", "Pumpkin is on the right of Red Cabinet.", "Pumpkin is above Red Cabinet."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Pumpkin is in front of Red Cabinet.\n1. Pumpkin is on the left of Red Cabinet.\n2. Pumpkin is below Red Cabinet.\n3. Pumpkin is behind Red Cabinet.\n4. Pumpkin is on the right of Red Cabinet.\n5. Pumpkin is above Red Cabinet.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 0, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 2, "is_correct": false, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tz_significant/chess/seq-06/000000-000036/target/frame-000036.color.png", "cap": ["Chessboard is on the left of Two Computers.", "Chessboard is on the right of Two Computers.", "Chessboard is above Two Computers.", "Chessboard is below Two Computers.", "Chessboard is in front of Two Computers.", "Chessboard is behind Two Computers."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Chessboard is on the left of Two Computers.\n1. Chessboard is on the right of Two Computers.\n2. Chessboard is above Two Computers.\n3. Chessboard is below Two Computers.\n4. Chessboard is in front of Two Computers.\n5. Chessboard is behind Two Computers.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 4, "cor_rela": "front", "cap_shuf": ["Chessboard is above Two Computers.", "Chessboard is below Two Computers.", "Chessboard is on the left of Two Computers.", "Chessboard is behind Two Computers.", "Chessboard is on the right of Two Computers.", "Chessboard is in front of Two Computers."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Chessboard is above Two Computers.\n1. Chessboard is below Two Computers.\n2. Chessboard is on the left of Two Computers.\n3. Chessboard is behind Two Computers.\n4. Chessboard is on the right of Two Computers.\n5. Chessboard is in front of Two Computers.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 5, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 1, "is_correct": false, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tz_significant/chess/seq-06/000000-000036/target/frame-000036.color.png", "cap": ["Two Computers is on the left of Chessboard.", "Two Computers is on the right of Chessboard.", "Two Computers is above Chessboard.", "Two Computers is below Chessboard.", "Two Computers is in front of Chessboard.", "Two Computers is behind Chessboard."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Two Computers is on the left of Chessboard.\n1. Two Computers is on the right of Chessboard.\n2. Two Computers is above Chessboard.\n3. Two Computers is below Chessboard.\n4. Two Computers is in front of Chessboard.\n5. Two Computers is behind Chessboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 5, "cor_rela": "behind", "cap_shuf": ["Two Computers is on the left of Chessboard.", "Two Computers is behind Chessboard.", "Two Computers is in front of Chessboard.", "Two Computers is on the right of Chessboard.", "Two Computers is above Chessboard.", "Two Computers is below Chessboard."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Two Computers is on the left of Chessboard.\n1. Two Computers is behind Chessboard.\n2. Two Computers is in front of Chessboard.\n3. Two Computers is on the right of Chessboard.\n4. Two Computers is above Chessboard.\n5. Two Computers is below Chessboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 1, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 4, "is_correct": false, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tz_significant/chess/seq-06/000000-000036/target/frame-000036.color.png", "cap": ["Chessboard is on the left of Whiteboard.", "Chessboard is on the right of Whiteboard.", "Chessboard is above Whiteboard.", "Chessboard is below Whiteboard.", "Chessboard is in front of Whiteboard.", "Chessboard is behind Whiteboard."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Chessboard is on the left of Whiteboard.\n1. Chessboard is on the right of Whiteboard.\n2. Chessboard is above Whiteboard.\n3. Chessboard is below Whiteboard.\n4. Chessboard is in front of Whiteboard.\n5. Chessboard is behind Whiteboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 1, "cor_rela": "right", "cap_shuf": ["Chessboard is below Whiteboard.", "Chessboard is above Whiteboard.", "Chessboard is in front of Whiteboard.", "Chessboard is behind Whiteboard.", "Chessboard is on the right of Whiteboard.", "Chessboard is on the left of Whiteboard."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Chessboard is below Whiteboard.\n1. Chessboard is above Whiteboard.\n2. Chessboard is in front of Whiteboard.\n3. Chessboard is behind Whiteboard.\n4. Chessboard is on the right of Whiteboard.\n5. Chessboard is on the left of Whiteboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 4, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 4, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tz_significant/chess/seq-06/000000-000036/target/frame-000036.color.png", "cap": ["Whiteboard is on the left of Chessboard.", "Whiteboard is on the right of Chessboard.", "Whiteboard is above Chessboard.", "Whiteboard is below Chessboard.", "Whiteboard is in front of Chessboard.", "Whiteboard is behind Chessboard."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Whiteboard is on the left of Chessboard.\n1. Whiteboard is on the right of Chessboard.\n2. Whiteboard is above Chessboard.\n3. Whiteboard is below Chessboard.\n4. Whiteboard is in front of Chessboard.\n5. Whiteboard is behind Chessboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 0, "cor_rela": "left", "cap_shuf": ["Whiteboard is below Chessboard.", "Whiteboard is on the right of Chessboard.", "Whiteboard is above Chessboard.", "Whiteboard is in front of Chessboard.", "Whiteboard is on the left of Chessboard.", "Whiteboard is behind Chessboard."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Whiteboard is below Chessboard.\n1. Whiteboard is on the right of Chessboard.\n2. Whiteboard is above Chessboard.\n3. Whiteboard is in front of Chessboard.\n4. Whiteboard is on the left of Chessboard.\n5. Whiteboard is behind Chessboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 4, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 4, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tz_significant/chess/seq-06/000098-000144/target/frame-000144.color.png", "cap": ["TV Monitor is on the left of Projector.", "TV Monitor is on the right of Projector.", "TV Monitor is above Projector.", "TV Monitor is below Projector.", "TV Monitor is in front of Projector.", "TV Monitor is behind Projector."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. TV Monitor is on the left of Projector.\n1. TV Monitor is on the right of Projector.\n2. TV Monitor is above Projector.\n3. TV Monitor is below Projector.\n4. TV Monitor is in front of Projector.\n5. TV Monitor is behind Projector.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 2, "cor_rela": "above", "cap_shuf": ["TV Monitor is below Projector.", "TV Monitor is on the left of Projector.", "TV Monitor is above Projector.", "TV Monitor is in front of Projector.", "TV Monitor is behind Projector.", "TV Monitor is on the right of Projector."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. TV Monitor is below Projector.\n1. TV Monitor is on the left of Projector.\n2. TV Monitor is above Projector.\n3. TV Monitor is in front of Projector.\n4. TV Monitor is behind Projector.\n5. TV Monitor is on the right of Projector.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 2, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 2, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tz_significant/chess/seq-06/000098-000144/target/frame-000144.color.png", "cap": ["Projector is on the left of TV Monitor.", "Projector is on the right of TV Monitor.", "Projector is above TV Monitor.", "Projector is below TV Monitor.", "Projector is in front of TV Monitor.", "Projector is behind TV Monitor."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Projector is on the left of TV Monitor.\n1. Projector is on the right of TV Monitor.\n2. Projector is above TV Monitor.\n3. Projector is below TV Monitor.\n4. Projector is in front of TV Monitor.\n5. Projector is behind TV Monitor.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 3, "cor_rela": "below", "cap_shuf": ["Projector is below TV Monitor.", "Projector is on the right of TV Monitor.", "Projector is above TV Monitor.", "Projector is on the left of TV Monitor.", "Projector is in front of TV Monitor.", "Projector is behind TV Monitor."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Projector is below TV Monitor.\n1. Projector is on the right of TV Monitor.\n2. Projector is above TV Monitor.\n3. Projector is on the left of TV Monitor.\n4. Projector is in front of TV Monitor.\n5. Projector is behind TV Monitor.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 0, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 0, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tx_significant/redkitchen/seq-11/000194-000220/target/frame-000220.color.png", "cap": ["Red Game Controller is on the left of Wood Table.", "Red Game Controller is on the right of Wood Table.", "Red Game Controller is above Wood Table.", "Red Game Controller is below Wood Table.", "Red Game Controller is in front of Wood Table.", "Red Game Controller is behind Wood Table."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Red Game Controller is on the left of Wood Table.\n1. Red Game Controller is on the right of Wood Table.\n2. Red Game Controller is above Wood Table.\n3. Red Game Controller is below Wood Table.\n4. Red Game Controller is in front of Wood Table.\n5. Red Game Controller is behind Wood Table.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 2, "cor_rela": "above", "cap_shuf": ["Red Game Controller is on the right of Wood Table.", "Red Game Controller is above Wood Table.", "Red Game Controller is below Wood Table.", "Red Game Controller is in front of Wood Table.", "Red Game Controller is behind Wood Table.", "Red Game Controller is on the left of Wood Table."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Red Game Controller is on the right of Wood Table.\n1. Red Game Controller is above Wood Table.\n2. Red Game Controller is below Wood Table.\n3. Red Game Controller is in front of Wood Table.\n4. Red Game Controller is behind Wood Table.\n5. Red Game Controller is on the left of Wood Table.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 1, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 0, "is_correct": false, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tx_significant/redkitchen/seq-11/000194-000220/target/frame-000220.color.png", "cap": ["Wood Table is on the left of Red Game Controller.", "Wood Table is on the right of Red Game Controller.", "Wood Table is above Red Game Controller.", "Wood Table is below Red Game Controller.", "Wood Table is in front of Red Game Controller.", "Wood Table is behind Red Game Controller."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Wood Table is on the left of Red Game Controller.\n1. Wood Table is on the right of Red Game Controller.\n2. Wood Table is above Red Game Controller.\n3. Wood Table is below Red Game Controller.\n4. Wood Table is in front of Red Game Controller.\n5. Wood Table is behind Red Game Controller.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 3, "cor_rela": "below", "cap_shuf": ["Wood Table is on the right of Red Game Controller.", "Wood Table is below Red Game Controller.", "Wood Table is above Red Game Controller.", "Wood Table is on the left of Red Game Controller.", "Wood Table is behind Red Game Controller.", "Wood Table is in front of Red Game Controller."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Wood Table is on the right of Red Game Controller.\n1. Wood Table is below Red Game Controller.\n2. Wood Table is above Red Game Controller.\n3. Wood Table is on the left of Red Game Controller.\n4. Wood Table is behind Red Game Controller.\n5. Wood Table is in front of Red Game Controller.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 1, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 1, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tx_significant/redkitchen/seq-11/000114-000141/target/frame-000141.color.png", "cap": ["Red Cabinet is on the left of Wood Table.", "Red Cabinet is on the right of Wood Table.", "Red Cabinet is above Wood Table.", "Red Cabinet is below Wood Table.", "Red Cabinet is in front of Wood Table.", "Red Cabinet is behind Wood Table."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Red Cabinet is on the left of Wood Table.\n1. Red Cabinet is on the right of Wood Table.\n2. Red Cabinet is above Wood Table.\n3. Red Cabinet is below Wood Table.\n4. Red Cabinet is in front of Wood Table.\n5. Red Cabinet is behind Wood Table.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 5, "cor_rela": "behind", "cap_shuf": ["Red Cabinet is above Wood Table.", "Red Cabinet is on the right of Wood Table.", "Red Cabinet is on the left of Wood Table.", "Red Cabinet is below Wood Table.", "Red Cabinet is in front of Wood Table.", "Red Cabinet is behind Wood Table."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Red Cabinet is above Wood Table.\n1. Red Cabinet is on the right of Wood Table.\n2. Red Cabinet is on the left of Wood Table.\n3. Red Cabinet is below Wood Table.\n4. Red Cabinet is in front of Wood Table.\n5. Red Cabinet is behind Wood Table.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 5, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 2, "is_correct": false, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tx_significant/redkitchen/seq-11/000114-000141/target/frame-000141.color.png", "cap": ["Wood Table is on the left of Red Cabinet.", "Wood Table is on the right of Red Cabinet.", "Wood Table is above Red Cabinet.", "Wood Table is below Red Cabinet.", "Wood Table is in front of Red Cabinet.", "Wood Table is behind Red Cabinet."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Wood Table is on the left of Red Cabinet.\n1. Wood Table is on the right of Red Cabinet.\n2. Wood Table is above Red Cabinet.\n3. Wood Table is below Red Cabinet.\n4. Wood Table is in front of Red Cabinet.\n5. Wood Table is behind Red Cabinet.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 4, "cor_rela": "front", "cap_shuf": ["Wood Table is behind Red Cabinet.", "Wood Table is on the right of Red Cabinet.", "Wood Table is below Red Cabinet.", "Wood Table is on the left of Red Cabinet.", "Wood Table is above Red Cabinet.", "Wood Table is in front of Red Cabinet."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Wood Table is behind Red Cabinet.\n1. Wood Table is on the right of Red Cabinet.\n2. Wood Table is below Red Cabinet.\n3. Wood Table is on the left of Red Cabinet.\n4. Wood Table is above Red Cabinet.\n5. Wood Table is in front of Red Cabinet.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 5, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 5, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tx_significant/redkitchen/seq-11/000553-000583/target/frame-000583.color.png", "cap": ["Mug is on the left of Wood Table.", "Mug is on the right of Wood Table.", "Mug is above Wood Table.", "Mug is below Wood Table.", "Mug is in front of Wood Table.", "Mug is behind Wood Table."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Mug is on the left of Wood Table.\n1. Mug is on the right of Wood Table.\n2. Mug is above Wood Table.\n3. Mug is below Wood Table.\n4. Mug is in front of Wood Table.\n5. Mug is behind Wood Table.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 2, "cor_rela": "above", "cap_shuf": ["Mug is in front of Wood Table.", "Mug is below Wood Table.", "Mug is on the left of Wood Table.", "Mug is on the right of Wood Table.", "Mug is behind Wood Table.", "Mug is above Wood Table."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Mug is in front of Wood Table.\n1. Mug is below Wood Table.\n2. Mug is on the left of Wood Table.\n3. Mug is on the right of Wood Table.\n4. Mug is behind Wood Table.\n5. Mug is above Wood Table.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 5, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 0, "is_correct": false, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tx_significant/redkitchen/seq-11/000553-000583/target/frame-000583.color.png", "cap": ["Wood Table is on the left of Mug.", "Wood Table is on the right of Mug.", "Wood Table is above Mug.", "Wood Table is below Mug.", "Wood Table is in front of Mug.", "Wood Table is behind Mug."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Wood Table is on the left of Mug.\n1. Wood Table is on the right of Mug.\n2. Wood Table is above Mug.\n3. Wood Table is below Mug.\n4. Wood Table is in front of Mug.\n5. Wood Table is behind Mug.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 3, "cor_rela": "below", "cap_shuf": ["Wood Table is above Mug.", "Wood Table is on the right of Mug.", "Wood Table is in front of Mug.", "Wood Table is below Mug.", "Wood Table is behind Mug.", "Wood Table is on the left of Mug."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Wood Table is above Mug.\n1. Wood Table is on the right of Mug.\n2. Wood Table is in front of Mug.\n3. Wood Table is below Mug.\n4. Wood Table is behind Mug.\n5. Wood Table is on the left of Mug.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 3, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 3, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tx_significant/pumpkin/seq-07/000547-000605/target/frame-000605.color.png", "cap": ["Blue Sofa is on the left of Red Cabinet.", "Blue Sofa is on the right of Red Cabinet.", "Blue Sofa is above Red Cabinet.", "Blue Sofa is below Red Cabinet.", "Blue Sofa is in front of Red Cabinet.", "Blue Sofa is behind Red Cabinet."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Blue Sofa is on the left of Red Cabinet.\n1. Blue Sofa is on the right of Red Cabinet.\n2. Blue Sofa is above Red Cabinet.\n3. Blue Sofa is below Red Cabinet.\n4. Blue Sofa is in front of Red Cabinet.\n5. Blue Sofa is behind Red Cabinet.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 4, "cor_rela": "front", "cap_shuf": ["Blue Sofa is below Red Cabinet.", "Blue Sofa is on the right of Red Cabinet.", "Blue Sofa is on the left of Red Cabinet.", "Blue Sofa is behind Red Cabinet.", "Blue Sofa is in front of Red Cabinet.", "Blue Sofa is above Red Cabinet."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Blue Sofa is below Red Cabinet.\n1. Blue Sofa is on the right of Red Cabinet.\n2. Blue Sofa is on the left of Red Cabinet.\n3. Blue Sofa is behind Red Cabinet.\n4. Blue Sofa is in front of Red Cabinet.\n5. Blue Sofa is above Red Cabinet.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 4, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 4, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tx_significant/pumpkin/seq-07/000547-000605/target/frame-000605.color.png", "cap": ["Red Cabinet is on the left of Blue Sofa.", "Red Cabinet is on the right of Blue Sofa.", "Red Cabinet is above Blue Sofa.", "Red Cabinet is below Blue Sofa.", "Red Cabinet is in front of Blue Sofa.", "Red Cabinet is behind Blue Sofa."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Red Cabinet is on the left of Blue Sofa.\n1. Red Cabinet is on the right of Blue Sofa.\n2. Red Cabinet is above Blue Sofa.\n3. Red Cabinet is below Blue Sofa.\n4. Red Cabinet is in front of Blue Sofa.\n5. Red Cabinet is behind Blue Sofa.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 5, "cor_rela": "behind", "cap_shuf": ["Red Cabinet is above Blue Sofa.", "Red Cabinet is on the right of Blue Sofa.", "Red Cabinet is behind Blue Sofa.", "Red Cabinet is below Blue Sofa.", "Red Cabinet is on the left of Blue Sofa.", "Red Cabinet is in front of Blue Sofa."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Red Cabinet is above Blue Sofa.\n1. Red Cabinet is on the right of Blue Sofa.\n2. Red Cabinet is behind Blue Sofa.\n3. Red Cabinet is below Blue Sofa.\n4. Red Cabinet is on the left of Blue Sofa.\n5. Red Cabinet is in front of Blue Sofa.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 2, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 2, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tx_significant/pumpkin/seq-07/000818-000887/target/frame-000887.color.png", "cap": ["Sink is on the left of Coffee Machine.", "Sink is on the right of Coffee Machine.", "Sink is above Coffee Machine.", "Sink is below Coffee Machine.", "Sink is in front of Coffee Machine.", "Sink is behind Coffee Machine."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Sink is on the left of Coffee Machine.\n1. Sink is on the right of Coffee Machine.\n2. Sink is above Coffee Machine.\n3. Sink is below Coffee Machine.\n4. Sink is in front of Coffee Machine.\n5. Sink is behind Coffee Machine.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 0, "cor_rela": "left", "cap_shuf": ["Sink is on the right of Coffee Machine.", "Sink is on the left of Coffee Machine.", "Sink is below Coffee Machine.", "Sink is above Coffee Machine.", "Sink is in front of Coffee Machine.", "Sink is behind Coffee Machine."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Sink is on the right of Coffee Machine.\n1. Sink is on the left of Coffee Machine.\n2. Sink is below Coffee Machine.\n3. Sink is above Coffee Machine.\n4. Sink is in front of Coffee Machine.\n5. Sink is behind Coffee Machine.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 1, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 1, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/tx_significant/pumpkin/seq-07/000818-000887/target/frame-000887.color.png", "cap": ["Coffee Machine is on the left of Sink.", "Coffee Machine is on the right of Sink.", "Coffee Machine is above Sink.", "Coffee Machine is below Sink.", "Coffee Machine is in front of Sink.", "Coffee Machine is behind Sink."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Coffee Machine is on the left of Sink.\n1. Coffee Machine is on the right of Sink.\n2. Coffee Machine is above Sink.\n3. Coffee Machine is below Sink.\n4. Coffee Machine is in front of Sink.\n5. Coffee Machine is behind Sink.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 1, "cor_rela": "right", "cap_shuf": ["Coffee Machine is on the right of Sink.", "Coffee Machine is below Sink.", "Coffee Machine is above Sink.", "Coffee Machine is in front of Sink.", "Coffee Machine is on the left of Sink.", "Coffee Machine is behind Sink."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Coffee Machine is on the right of Sink.\n1. Coffee Machine is below Sink.\n2. Coffee Machine is above Sink.\n3. Coffee Machine is in front of Sink.\n4. Coffee Machine is on the left of Sink.\n5. Coffee Machine is behind Sink.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 0, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 0, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/phi_significant/heads/seq-01/000208-000242/target/frame-000242.color.png", "cap": ["Mannequin Head is on the left of Redbull Can.", "Mannequin Head is on the right of Redbull Can.", "Mannequin Head is above Redbull Can.", "Mannequin Head is below Redbull Can.", "Mannequin Head is in front of Redbull Can.", "Mannequin Head is behind Redbull Can."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Mannequin Head is on the left of Redbull Can.\n1. Mannequin Head is on the right of Redbull Can.\n2. Mannequin Head is above Redbull Can.\n3. Mannequin Head is below Redbull Can.\n4. Mannequin Head is in front of Redbull Can.\n5. Mannequin Head is behind Redbull Can.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 1, "cor_rela": "right", "cap_shuf": ["Mannequin Head is behind Redbull Can.", "Mannequin Head is below Redbull Can.", "Mannequin Head is in front of Redbull Can.", "Mannequin Head is on the right of Redbull Can.", "Mannequin Head is on the left of Redbull Can.", "Mannequin Head is above Redbull Can."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Mannequin Head is behind Redbull Can.\n1. Mannequin Head is below Redbull Can.\n2. Mannequin Head is in front of Redbull Can.\n3. Mannequin Head is on the right of Redbull Can.\n4. Mannequin Head is on the left of Redbull Can.\n5. Mannequin Head is above Redbull Can.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 3, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 3, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/phi_significant/heads/seq-01/000208-000242/target/frame-000242.color.png", "cap": ["Redbull Can is on the left of Mannequin Head.", "Redbull Can is on the right of Mannequin Head.", "Redbull Can is above Mannequin Head.", "Redbull Can is below Mannequin Head.", "Redbull Can is in front of Mannequin Head.", "Redbull Can is behind Mannequin Head."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Redbull Can is on the left of Mannequin Head.\n1. Redbull Can is on the right of Mannequin Head.\n2. Redbull Can is above Mannequin Head.\n3. Redbull Can is below Mannequin Head.\n4. Redbull Can is in front of Mannequin Head.\n5. Redbull Can is behind Mannequin Head.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 0, "cor_rela": "left", "cap_shuf": ["Redbull Can is in front of Mannequin Head.", "Redbull Can is on the right of Mannequin Head.", "Redbull Can is on the left of Mannequin Head.", "Redbull Can is behind Mannequin Head.", "Redbull Can is below Mannequin Head.", "Redbull Can is above Mannequin Head."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Redbull Can is in front of Mannequin Head.\n1. Redbull Can is on the right of Mannequin Head.\n2. Redbull Can is on the left of Mannequin Head.\n3. Redbull Can is behind Mannequin Head.\n4. Redbull Can is below Mannequin Head.\n5. Redbull Can is above Mannequin Head.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 2, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 2, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/phi_significant/heads/seq-01/000600-000631/target/frame-000631.color.png", "cap": ["White Table is on the left of Keyboard.", "White Table is on the right of Keyboard.", "White Table is above Keyboard.", "White Table is below Keyboard.", "White Table is in front of Keyboard.", "White Table is behind Keyboard."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. White Table is on the left of Keyboard.\n1. White Table is on the right of Keyboard.\n2. White Table is above Keyboard.\n3. White Table is below Keyboard.\n4. White Table is in front of Keyboard.\n5. White Table is behind Keyboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 3, "cor_rela": "below", "cap_shuf": ["White Table is in front of Keyboard.", "White Table is on the left of Keyboard.", "White Table is below Keyboard.", "White Table is behind Keyboard.", "White Table is on the right of Keyboard.", "White Table is above Keyboard."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. White Table is in front of Keyboard.\n1. White Table is on the left of Keyboard.\n2. White Table is below Keyboard.\n3. White Table is behind Keyboard.\n4. White Table is on the right of Keyboard.\n5. White Table is above Keyboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 2, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 5, "is_correct": false, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/phi_significant/heads/seq-01/000600-000631/target/frame-000631.color.png", "cap": ["Keyboard is on the left of White Table.", "Keyboard is on the right of White Table.", "Keyboard is above White Table.", "Keyboard is below White Table.", "Keyboard is in front of White Table.", "Keyboard is behind White Table."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Keyboard is on the left of White Table.\n1. Keyboard is on the right of White Table.\n2. Keyboard is above White Table.\n3. Keyboard is below White Table.\n4. Keyboard is in front of White Table.\n5. Keyboard is behind White Table.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 2, "cor_rela": "above", "cap_shuf": ["Keyboard is above White Table.", "Keyboard is below White Table.", "Keyboard is on the left of White Table.", "Keyboard is behind White Table.", "Keyboard is on the right of White Table.", "Keyboard is in front of White Table."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Keyboard is above White Table.\n1. Keyboard is below White Table.\n2. Keyboard is on the left of White Table.\n3. Keyboard is behind White Table.\n4. Keyboard is on the right of White Table.\n5. Keyboard is in front of White Table.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 0, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 0, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/phi_significant/chess/seq-01/000771-000833/target/frame-000833.color.png", "cap": ["Wood Shelf is on the left of Projector.", "Wood Shelf is on the right of Projector.", "Wood Shelf is above Projector.", "Wood Shelf is below Projector.", "Wood Shelf is in front of Projector.", "Wood Shelf is behind Projector."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Wood Shelf is on the left of Projector.\n1. Wood Shelf is on the right of Projector.\n2. Wood Shelf is above Projector.\n3. Wood Shelf is below Projector.\n4. Wood Shelf is in front of Projector.\n5. Wood Shelf is behind Projector.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 0, "cor_rela": "left", "cap_shuf": ["Wood Shelf is on the left of Projector.", "Wood Shelf is behind Projector.", "Wood Shelf is in front of Projector.", "Wood Shelf is on the right of Projector.", "Wood Shelf is above Projector.", "Wood Shelf is below Projector."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Wood Shelf is on the left of Projector.\n1. Wood Shelf is behind Projector.\n2. Wood Shelf is in front of Projector.\n3. Wood Shelf is on the right of Projector.\n4. Wood Shelf is above Projector.\n5. Wood Shelf is below Projector.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 0, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 0, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/phi_significant/chess/seq-01/000771-000833/target/frame-000833.color.png", "cap": ["Projector is on the left of Wood Shelf.", "Projector is on the right of Wood Shelf.", "Projector is above Wood Shelf.", "Projector is below Wood Shelf.", "Projector is in front of Wood Shelf.", "Projector is behind Wood Shelf."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Projector is on the left of Wood Shelf.\n1. Projector is on the right of Wood Shelf.\n2. Projector is above Wood Shelf.\n3. Projector is below Wood Shelf.\n4. Projector is in front of Wood Shelf.\n5. Projector is behind Wood Shelf.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 1, "cor_rela": "right", "cap_shuf": ["Projector is below Wood Shelf.", "Projector is above Wood Shelf.", "Projector is in front of Wood Shelf.", "Projector is behind Wood Shelf.", "Projector is on the right of Wood Shelf.", "Projector is on the left of Wood Shelf."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Projector is below Wood Shelf.\n1. Projector is above Wood Shelf.\n2. Projector is in front of Wood Shelf.\n3. Projector is behind Wood Shelf.\n4. Projector is on the right of Wood Shelf.\n5. Projector is on the left of Wood Shelf.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 4, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 4, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/phi_significant/chess/seq-01/000544-000562/target/frame-000562.color.png", "cap": ["Part of Chessboard is on the left of Projector.", "Part of Chessboard is on the right of Projector.", "Part of Chessboard is above Projector.", "Part of Chessboard is below Projector.", "Part of Chessboard is in front of Projector.", "Part of Chessboard is behind Projector."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Part of Chessboard is on the left of Projector.\n1. Part of Chessboard is on the right of Projector.\n2. Part of Chessboard is above Projector.\n3. Part of Chessboard is below Projector.\n4. Part of Chessboard is in front of Projector.\n5. Part of Chessboard is behind Projector.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 4, "cor_rela": "front", "cap_shuf": ["Part of Chessboard is in front of Projector.", "Part of Chessboard is below Projector.", "Part of Chessboard is behind Projector.", "Part of Chessboard is on the right of Projector.", "Part of Chessboard is on the left of Projector.", "Part of Chessboard is above Projector."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Part of Chessboard is in front of Projector.\n1. Part of Chessboard is below Projector.\n2. Part of Chessboard is behind Projector.\n3. Part of Chessboard is on the right of Projector.\n4. Part of Chessboard is on the left of Projector.\n5. Part of Chessboard is above Projector.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 0, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 1, "is_correct": false, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/phi_significant/chess/seq-01/000544-000562/target/frame-000562.color.png", "cap": ["Projector is on the left of Part of Chessboard.", "Projector is on the right of Part of Chessboard.", "Projector is above Part of Chessboard.", "Projector is below Part of Chessboard.", "Projector is in front of Part of Chessboard.", "Projector is behind Part of Chessboard."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Projector is on the left of Part of Chessboard.\n1. Projector is on the right of Part of Chessboard.\n2. Projector is above Part of Chessboard.\n3. Projector is below Part of Chessboard.\n4. Projector is in front of Part of Chessboard.\n5. Projector is behind Part of Chessboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 5, "cor_rela": "behind", "cap_shuf": ["Projector is on the left of Part of Chessboard.", "Projector is behind Part of Chessboard.", "Projector is above Part of Chessboard.", "Projector is in front of Part of Chessboard.", "Projector is below Part of Chessboard.", "Projector is on the right of Part of Chessboard."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Projector is on the left of Part of Chessboard.\n1. Projector is behind Part of Chessboard.\n2. Projector is above Part of Chessboard.\n3. Projector is in front of Part of Chessboard.\n4. Projector is below Part of Chessboard.\n5. Projector is on the right of Part of Chessboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 1, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 0, "is_correct": false, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/ty_significant/office/seq-03/000620-000643/target/frame-000643.color.png", "cap": ["CPU is on the left of Office Chair.", "CPU is on the right of Office Chair.", "CPU is above Office Chair.", "CPU is below Office Chair.", "CPU is in front of Office Chair.", "CPU is behind Office Chair."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. CPU is on the left of Office Chair.\n1. CPU is on the right of Office Chair.\n2. CPU is above Office Chair.\n3. CPU is below Office Chair.\n4. CPU is in front of Office Chair.\n5. CPU is behind Office Chair.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 1, "cor_rela": "right", "cap_shuf": ["CPU is below Office Chair.", "CPU is on the right of Office Chair.", "CPU is above Office Chair.", "CPU is in front of Office Chair.", "CPU is on the left of Office Chair.", "CPU is behind Office Chair."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. CPU is below Office Chair.\n1. CPU is on the right of Office Chair.\n2. CPU is above Office Chair.\n3. CPU is in front of Office Chair.\n4. CPU is on the left of Office Chair.\n5. CPU is behind Office Chair.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 1, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 1, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/ty_significant/office/seq-03/000620-000643/target/frame-000643.color.png", "cap": ["Office Chair is on the left of CPU.", "Office Chair is on the right of CPU.", "Office Chair is above CPU.", "Office Chair is below CPU.", "Office Chair is in front of CPU.", "Office Chair is behind CPU."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Office Chair is on the left of CPU.\n1. Office Chair is on the right of CPU.\n2. Office Chair is above CPU.\n3. Office Chair is below CPU.\n4. Office Chair is in front of CPU.\n5. Office Chair is behind CPU.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 0, "cor_rela": "left", "cap_shuf": ["Office Chair is below CPU.", "Office Chair is on the left of CPU.", "Office Chair is above CPU.", "Office Chair is in front of CPU.", "Office Chair is behind CPU.", "Office Chair is on the right of CPU."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Office Chair is below CPU.\n1. Office Chair is on the left of CPU.\n2. Office Chair is above CPU.\n3. Office Chair is in front of CPU.\n4. Office Chair is behind CPU.\n5. Office Chair is on the right of CPU.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 1, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 1, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/ty_significant/office/seq-03/000061-000096/target/frame-000096.color.png", "cap": ["Headphone is on the left of Keyboard.", "Headphone is on the right of Keyboard.", "Headphone is above Keyboard.", "Headphone is below Keyboard.", "Headphone is in front of Keyboard.", "Headphone is behind Keyboard."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Headphone is on the left of Keyboard.\n1. Headphone is on the right of Keyboard.\n2. Headphone is above Keyboard.\n3. Headphone is below Keyboard.\n4. Headphone is in front of Keyboard.\n5. Headphone is behind Keyboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 0, "cor_rela": "left", "cap_shuf": ["Headphone is below Keyboard.", "Headphone is on the right of Keyboard.", "Headphone is above Keyboard.", "Headphone is in front of Keyboard.", "Headphone is on the left of Keyboard.", "Headphone is behind Keyboard."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Headphone is below Keyboard.\n1. Headphone is on the right of Keyboard.\n2. Headphone is above Keyboard.\n3. Headphone is in front of Keyboard.\n4. Headphone is on the left of Keyboard.\n5. Headphone is behind Keyboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 4, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 4, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/ty_significant/office/seq-03/000061-000096/target/frame-000096.color.png", "cap": ["Keyboard is on the left of Headphone.", "Keyboard is on the right of Headphone.", "Keyboard is above Headphone.", "Keyboard is below Headphone.", "Keyboard is in front of Headphone.", "Keyboard is behind Headphone."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Keyboard is on the left of Headphone.\n1. Keyboard is on the right of Headphone.\n2. Keyboard is above Headphone.\n3. Keyboard is below Headphone.\n4. Keyboard is in front of Headphone.\n5. Keyboard is behind Headphone.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 1, "cor_rela": "right", "cap_shuf": ["Keyboard is below Headphone.", "Keyboard is on the left of Headphone.", "Keyboard is above Headphone.", "Keyboard is in front of Headphone.", "Keyboard is behind Headphone.", "Keyboard is on the right of Headphone."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Keyboard is below Headphone.\n1. Keyboard is on the left of Headphone.\n2. Keyboard is above Headphone.\n3. Keyboard is in front of Headphone.\n4. Keyboard is behind Headphone.\n5. Keyboard is on the right of Headphone.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 5, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 5, "is_correct": true, "is_parse": true}
{"img_path": "/home/u5u/kdeng.u5u/spatial-reasoning-of-LMs/demo/single-dof-camera-motion-demo/ty_significant/office/seq-03/000061-000096/target/frame-000096.color.png", "cap": ["Headphone is on the left of Keyboard.", "Headphone is on the right of Keyboard.", "Headphone is above Keyboard.", "Headphone is below Keyboard.", "Headphone is in front of Keyboard.", "Headphone is behind Keyboard."], "prompt": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Headphone is on the left of Keyboard.\n1. Headphone is on the right of Keyboard.\n2. Headphone is above Keyboard.\n3. Headphone is below Keyboard.\n4. Headphone is in front of Keyboard.\n5. Headphone is behind Keyboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx": 0, "cor_rela": "left", "cap_shuf": ["Headphone is below Keyboard.", "Headphone is on the right of Keyboard.", "Headphone is above Keyboard.", "Headphone is on the left of Keyboard.", "Headphone is in front of Keyboard.", "Headphone is behind Keyboard."], "prompt_shuf": "<input>\nYou are given an image, and a set of captions describing the relation of objects in the image.\n</inputs>\n\n<task>\nYou need to select the caption that best describes the image.\n</task>\n\n<captions>\n0. Headphone is below Keyboard.\n1. Headphone is on the right of Keyboard.\n2. Headphone is above Keyboard.\n3. Headphone is on the left of Keyboard.\n4. Headphone is in front of Keyboard.\n5. Headphone is behind Keyboard.\n</captions>\n\n<output-format>\nPlease output the index of the selected caption in the <ans></ans> XML tag. Do not output any other text.\n</output-format>", "cor_idx_shuf": 3, "vlm_id": "Qwen/Qwen2.5-VL-72B-Instruct", "pred": 3, "is_correct": true, "is_parse": true}
